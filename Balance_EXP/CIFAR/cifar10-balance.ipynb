{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Subset\n\nimport random\nfrom copy import deepcopy\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\n\nfrom imblearn.metrics import (geometric_mean_score, sensitivity_score, \n                              specificity_score)\nfrom sklearn.metrics import (balanced_accuracy_score, precision_score, \n                             recall_score, f1_score)\n\n\nimport scipy as sc\nimport matplotlib.style\n\nparams = {'legend.fontsize': 14,\n          'axes.labelsize': 14,\n          'axes.titlesize': 14,\n          'xtick.labelsize' :14,\n          'ytick.labelsize': 13,\n          'grid.color': 'k',\n          'grid.linestyle': ':',\n          'grid.linewidth': 0.8,\n          'mathtext.fontset' : 'stix',\n          'mathtext.rm'      : 'serif',\n          'font.family'      : 'serif',\n          'font.serif'       : \"Times New Roman\", # or \"Times\"          \n         }\nmatplotlib.rcParams.update(params)","metadata":{"_uuid":"96b35fc3-b665-41e1-bc8a-50ab40307245","_cell_guid":"aab6bd82-dae4-4f76-bbc2-a400c6b4fae0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-19T21:22:37.914331Z","iopub.execute_input":"2022-03-19T21:22:37.914687Z","iopub.status.idle":"2022-03-19T21:22:40.68446Z","shell.execute_reply.started":"2022-03-19T21:22:37.914586Z","shell.execute_reply":"2022-03-19T21:22:40.683718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    print(\"life is good\")\n    \ndevice = torch.device(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2022-03-19T21:22:40.6861Z","iopub.execute_input":"2022-03-19T21:22:40.688056Z","iopub.status.idle":"2022-03-19T21:22:40.733489Z","shell.execute_reply.started":"2022-03-19T21:22:40.688025Z","shell.execute_reply":"2022-03-19T21:22:40.731497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = 'CIFAR-10'\nbatch_size = 32\nval_size = 0.2\nepochs=200","metadata":{"execution":{"iopub.status.busy":"2022-03-19T21:22:40.735267Z","iopub.execute_input":"2022-03-19T21:22:40.7362Z","iopub.status.idle":"2022-03-19T21:22:40.7427Z","shell.execute_reply.started":"2022-03-19T21:22:40.736161Z","shell.execute_reply":"2022-03-19T21:22:40.741906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if dataset == 'CIFAR-10':\n    def seed_worker(worker_id):\n        worker_seed = torch.initial_seed() % 2**32\n        numpy.random.seed(worker_seed)\n        random.seed(worker_seed)\n\n    g = torch.Generator()\n    g.manual_seed(1)\n\n    train_transform = transforms.Compose([\n            util.Cutout(num_cutouts=2, size=8, p=0.8),\n            transforms.RandomCrop(32, padding=4),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n        ])\n    \n    test_transform = transforms.Compose([transforms.ToTensor(),\n                                             transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n                                             ])\n    \n    print('Datasets are being downloaded...')\n\n    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n\n    train_indices, val_indices, _, _ = train_test_split(\n    range(len(trainset)),\n    trainset.targets,\n    stratify=trainset.targets,\n    test_size=val_size\n    )\n\n    train_split = Subset(trainset, train_indices)\n    val_split = Subset(trainset, val_indices)\n\n    trainloader = DataLoader(train_split, batch_size=batch_size, shuffle=True, worker_init_fn=seed_worker, generator=g)\n    validloader = DataLoader(val_split, batch_size=batch_size, shuffle=True, worker_init_fn=seed_worker, generator=g)\n    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker, generator=g)\n\n    classes = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n    \n    output_size_network = len(classes)\n\n    print('Download finished!')\n\nelif dataset == 'CIFAR-100':\n    def seed_worker(worker_id):\n        worker_seed = torch.initial_seed() % 2**32\n        numpy.random.seed(worker_seed)\n        random.seed(worker_seed)\n\n    g = torch.Generator()\n    g.manual_seed(2)\n    \n    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n    print('Datasets are being downloaded...')\n\n    trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n    testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n\n    train_indices, val_indices, _, _ = train_test_split(\n    range(len(trainset)),\n    trainset.targets,\n    stratify=trainset.targets,\n    test_size=val_size\n    )\n\n    train_split = Subset(trainset, train_indices)\n    val_split = Subset(trainset, val_indices)\n\n    trainloader = DataLoader(train_split, batch_size=batch_size, shuffle=True, worker_init_fn=seed_worker, generator=g)\n    validloader = DataLoader(val_split, batch_size=batch_size, shuffle=True, worker_init_fn=seed_worker, generator=g)\n    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker, generator=g)\n\n    classes = ('apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', \n                  'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', \n                  'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', \n                  'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', \n                  'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', \n                  'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', \n                  'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm')\n    \n    output_size_network = len(classes)\n    \n    print(f'Download finished!')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T21:22:40.74498Z","iopub.execute_input":"2022-03-19T21:22:40.745516Z","iopub.status.idle":"2022-03-19T21:22:51.197121Z","shell.execute_reply.started":"2022-03-19T21:22:40.74548Z","shell.execute_reply":"2022-03-19T21:22:51.196306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    \"\"\"\n    A residual block as defined by He et al.\n    \"\"\"\n\n    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):\n        super(ResidualBlock, self).__init__()\n        self.conv_res1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n                                   padding=padding, stride=stride, bias=False)\n        self.conv_res1_bn = nn.BatchNorm2d(num_features=out_channels, momentum=0.9)\n        self.conv_res2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size,\n                                   padding=padding, bias=False)\n        self.conv_res2_bn = nn.BatchNorm2d(num_features=out_channels, momentum=0.9)\n\n        if stride != 1:\n            # in case stride is not set to 1, we need to downsample the residual so that\n            # the dimensions are the same when we add them together\n            self.downsample = nn.Sequential(\n                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(num_features=out_channels, momentum=0.9)\n            )\n        else:\n            self.downsample = None\n\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        residual = x\n\n        out = self.relu(self.conv_res1_bn(self.conv_res1(x)))\n        out = self.conv_res2_bn(self.conv_res2(out))\n\n        if self.downsample is not None:\n            residual = self.downsample(residual)\n\n        out = self.relu(out)\n        out += residual\n        return out\n\n\nclass Net(nn.Module):\n    \"\"\"\n    A Residual network.\n    \"\"\"\n    def __init__(self):\n        super(Net, self).__init__()\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(num_features=64, momentum=0.9),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(num_features=128, momentum=0.9),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            ResidualBlock(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(num_features=256, momentum=0.9),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(num_features=256, momentum=0.9),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            ResidualBlock(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        self.fc = nn.Linear(in_features=1024, out_features=output_size_network, bias=True)\n\n    def forward(self, x):\n        out = self.conv(x)\n        out = out.view(-1, out.shape[1] * out.shape[2] * out.shape[3])\n        out = self.fc(out)\n        return out\n\nmodel = Net()\nmodel = nn.DataParallel(model)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T21:22:54.160963Z","iopub.execute_input":"2022-03-19T21:22:54.161214Z","iopub.status.idle":"2022-03-19T21:22:54.27226Z","shell.execute_reply.started":"2022-03-19T21:22:54.161181Z","shell.execute_reply":"2022-03-19T21:22:54.271546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\nval_loss_min1 = np.Inf","metadata":{"execution":{"iopub.status.busy":"2022-03-19T21:22:54.791496Z","iopub.execute_input":"2022-03-19T21:22:54.791744Z","iopub.status.idle":"2022-03-19T21:22:54.804954Z","shell.execute_reply.started":"2022-03-19T21:22:54.791708Z","shell.execute_reply":"2022-03-19T21:22:54.804299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss_hist = []\nval_loss_hist = []\n\n    \nprint('-------------------')\nprint('MODEL: ResNet9')\nprint('-------------------')\n\nnp.random.seed(1)\ntorch.manual_seed(1)\nrandom.seed(1)\ntorch.cuda.manual_seed(1)\n\nfor epoch in range(1, epochs+1):  \n    train_loss = 0.0\n    val_loss = 0.0\n\n    model.train()\n    for data, labels in trainloader:\n        data, labels = data.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(data)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    model.eval()\n\n    with torch.no_grad():\n        for data, labels in validloader:\n            data, labels = data.to(device), labels.to(device)\n            outputs = model(data)\n            loss = criterion(outputs, labels)\n            \n            val_loss += loss.item()\n\n\n    train_loss = train_loss/len(trainloader)\n    val_loss = val_loss/len(validloader)\n    train_loss_hist.append(train_loss)\n    val_loss_hist.append(val_loss)\n\n    print('Epoch: {} \\tTraining Loss: {:.3f} \\tValidation Loss: {:.3f}'.format( \n        epoch, train_loss, val_loss))\n \n\n    if val_loss <= val_loss_min[network][seed-1]:\n        print('Validation loss decreased ({:.3f} --> {:.3f}).  Saving model ...'.format(\n        val_loss_min1,\n        val_loss))\n        torch.save({\n            'model'+'_state_dict': deepcopy(model.state_dict()),\n            'optimizer'+'_state_dict': deepcopy(optimizer.state_dict()),\n            'epoch': epoch\n                }, 'balance_cifar'+str('.pt'))\n        val_loss_min1 = val_loss","metadata":{"execution":{"iopub.status.busy":"2022-03-19T21:22:54.806157Z","iopub.execute_input":"2022-03-19T21:22:54.806556Z","iopub.status.idle":"2022-03-20T02:58:16.423429Z","shell.execute_reply.started":"2022-03-19T21:22:54.806521Z","shell.execute_reply":"2022-03-20T02:58:16.422595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\")\n\ncheckpoint1 = torch.load('balance_cifar.pt')\nmodel1.load_state_dict(checkpoint1['model_state_dict'])\noptimizer1.load_state_dict(checkpoint1['optimizer_state_dict'])\nepoch1 = checkpoint1['epoch']\nmodel1.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T02:58:20.563481Z","iopub.execute_input":"2022-03-20T02:58:20.563903Z","iopub.status.idle":"2022-03-20T02:58:20.729165Z","shell.execute_reply.started":"2022-03-20T02:58:20.56386Z","shell.execute_reply":"2022-03-20T02:58:20.728481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_updated = model1","metadata":{"execution":{"iopub.status.busy":"2022-03-20T02:58:20.73044Z","iopub.execute_input":"2022-03-20T02:58:20.730849Z","iopub.status.idle":"2022-03-20T02:58:20.736546Z","shell.execute_reply.started":"2022-03-20T02:58:20.730811Z","shell.execute_reply":"2022-03-20T02:58:20.735789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"global_accuracy = []\ntest_loss_hist = []\nlabels_list = []\npred_list= []\nclass_accuracy_model =[]\n        \ntest_loss = 0.0\ncorrect = 0\ntotal = 0\n    \ncorrect_pred = {classname: 0 for classname in classes}\ntotal_pred = {classname: 0 for classname in classes}\n        \nmodel_updated.eval()\nwith torch.no_grad():\n    for data, labels in testloader:\n        images, labels = data.to(device), labels.to(device)\n        output = model_updated(images)\n    \n        loss = criterion(output, labels)\n        test_loss += loss.item()\n\n        _, pred = torch.max(output, 1)    \n\n        total += labels.size(0)\n        correct += (pred == labels).sum().item()\n                \n        for label, p in zip(labels, pred):\n            if label == p:\n                correct_pred[classes[label]] += 1\n            total_pred[classes[label]] += 1\n\n        pred = pred.cpu().detach().numpy()\n        labels = labels.cpu().detach().numpy()\n\n        pred_list.append(pred)\n        labels_list.append(labels)\n\ntest_loss = test_loss/len(testloader)\ntest_loss_hist.append(test_loss)\n        \naccuracy = 100 * correct / total\nglobal_accuracy.append(accuracy)\n        \nfor classname, correct_count in correct_pred.items():\n    model_seed_accuracy = 100 * float(correct_count) / total_pred[classname]\n    class_accuracy_model.append(model_seed_accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T02:58:20.737772Z","iopub.execute_input":"2022-03-20T02:58:20.738225Z","iopub.status.idle":"2022-03-20T02:58:36.83622Z","shell.execute_reply.started":"2022-03-20T02:58:20.738189Z","shell.execute_reply":"2022-03-20T02:58:36.835472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Test Loss for ResNet9: {:.3f}'.format(test_loss_hist))\nprint('Accuracy for ResNet9: {:.3f}%'.format(global_accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-03-20T02:58:36.837507Z","iopub.execute_input":"2022-03-20T02:58:36.837738Z","iopub.status.idle":"2022-03-20T02:58:36.846488Z","shell.execute_reply.started":"2022-03-20T02:58:36.837707Z","shell.execute_reply":"2022-03-20T02:58:36.845818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_list = [item for sublist in pred_list for item in sublist]\nlabels_list = [item for sublist in labels_list for item in sublist]\n\npred_model1 = pred_list.tolist()\nlabels_list = labels_list[0].tolist()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T02:58:36.864295Z","iopub.execute_input":"2022-03-20T02:58:36.864993Z","iopub.status.idle":"2022-03-20T02:58:36.890724Z","shell.execute_reply.started":"2022-03-20T02:58:36.864957Z","shell.execute_reply":"2022-03-20T02:58:36.890068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_micro = f1_score(labels_list, pred_model1, average='micro')\nf1_macro = f1_score(labels_list, pred_model1, average='macro')\n        \ngmean_micro = geometric_mean_score(labels_list, pred_model1, average='micro')\ngmean_macro = geometric_mean_score(labels_list, pred_model1, average='macro')\n        \nbac = balanced_accuracy_score(labels_list, pred_model1)\nbac_adj = balanced_accuracy_score(labels_list, pred_model1, adjusted=True)\n        \nsens_micro = sensitivity_score(labels_list, pred_model1, average='micro')\nsens_macro = sensitivity_score(labels_list, pred_model1, average='macro')\n        \nspec_micro = specificity_score(labels_list, pred_model1, average='micro')\nspec_macro = specificity_score(labels_list, pred_model1, average='macro')\n                                       \nprec_micro = precision_score(labels_list, pred_model1, average='micro')\nprec_macro = precision_score(labels_list, pred_model1, average='macro')\n                                       \nrec_micro = recall_score(labels_list, pred_model1, average='micro')\nrec_macro = recall_score(labels_list, pred_model1, average='macro')","metadata":{"execution":{"iopub.status.busy":"2022-03-20T02:58:36.89231Z","iopub.execute_input":"2022-03-20T02:58:36.892628Z","iopub.status.idle":"2022-03-20T02:58:37.519266Z","shell.execute_reply.started":"2022-03-20T02:58:36.892593Z","shell.execute_reply":"2022-03-20T02:58:37.518526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics_list = [f1_micro, f1_macro, gmean_micro, gmean_macro, bac, bac_adj, sens_micro, sens_macro, spec_micro, spec_macro,\n                prec_micro, prec_macro, rec_micro, rec_macro]\n\nnames = [\"F1 Micro\", \"F1 Macro\", \"GMean Micro\", \"GMean Macro\", \"Balanced Accuracy\", \"Adjusted Balanced Accuracy\", \"Sensitivity Micro\", \"Sensitivity Macro\", \"Specificity Micro\", \n            \"Specificity Macro\", \"Precision Micro\", \"Precision Macro\", \"Recall Micro\", \"Recall Macro\"]\n\nfor metric, name in zip(metrics_list, names): \n    print('---------------')\n    print('MODEL: ResNet9')\n    print('METRIC:', name)\n    print('---------------')\n    print(' {:.2f}'.format(metric))","metadata":{"execution":{"iopub.status.busy":"2022-03-20T02:58:37.520611Z","iopub.execute_input":"2022-03-20T02:58:37.520996Z","iopub.status.idle":"2022-03-20T02:58:37.575976Z","shell.execute_reply.started":"2022-03-20T02:58:37.52096Z","shell.execute_reply":"2022-03-20T02:58:37.575306Z"},"trusted":true},"execution_count":null,"outputs":[]}]}