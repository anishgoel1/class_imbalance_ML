{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a7cb8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T08:16:17.352816Z",
     "iopub.status.busy": "2022-03-21T08:16:17.351066Z",
     "iopub.status.idle": "2022-03-21T08:16:22.991128Z",
     "shell.execute_reply": "2022-03-21T08:16:22.990413Z",
     "shell.execute_reply.started": "2022-03-21T00:42:24.050704Z"
    },
    "papermill": {
     "duration": 5.665822,
     "end_time": "2022-03-21T08:16:22.991316",
     "exception": false,
     "start_time": "2022-03-21T08:16:17.325494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701aa18c90154b458e65f2b79b37787e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca859a310ed464abc64ebe561529949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b3a0ff56e84f3e820f7fa8563d91c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702f7b28066a46daaa718a4c0712078a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /usr/local/src/pytorch/torch/csrc/utils/tensor_numpy.cpp:174.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import mnist_balance_generator\n",
    "from mnist_balance_generator import *\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import models\n",
    "\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.metrics import (geometric_mean_score, sensitivity_score, \n",
    "                              specificity_score)\n",
    "from sklearn.metrics import (balanced_accuracy_score, precision_score, \n",
    "                             recall_score, f1_score)\n",
    "\n",
    "\n",
    "import scipy as sc\n",
    "import matplotlib.style\n",
    "\n",
    "params = {'legend.fontsize': 14,\n",
    "          'axes.labelsize': 14,\n",
    "          'axes.titlesize': 14,\n",
    "          'xtick.labelsize' :14,\n",
    "          'ytick.labelsize': 13,\n",
    "          'grid.color': 'k',\n",
    "          'grid.linestyle': ':',\n",
    "          'grid.linewidth': 0.8,\n",
    "          'mathtext.fontset' : 'stix',\n",
    "          'mathtext.rm'      : 'serif',\n",
    "          'font.family'      : 'serif',\n",
    "          'font.serif'       : \"Times New Roman\", # or \"Times\"          \n",
    "         }\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f602f00b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T08:16:23.096571Z",
     "iopub.status.busy": "2022-03-21T08:16:23.095895Z",
     "iopub.status.idle": "2022-03-21T08:16:23.100221Z",
     "shell.execute_reply": "2022-03-21T08:16:23.100803Z",
     "shell.execute_reply.started": "2022-03-21T00:42:28.611206Z"
    },
    "papermill": {
     "duration": 0.082378,
     "end_time": "2022-03-21T08:16:23.100984",
     "exception": false,
     "start_time": "2022-03-21T08:16:23.018606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "life is good\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"life is good\")\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcfb697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T08:16:23.159209Z",
     "iopub.status.busy": "2022-03-21T08:16:23.158454Z",
     "iopub.status.idle": "2022-03-21T08:16:23.160407Z",
     "shell.execute_reply": "2022-03-21T08:16:23.160781Z",
     "shell.execute_reply.started": "2022-03-21T00:42:28.653614Z"
    },
    "papermill": {
     "duration": 0.032528,
     "end_time": "2022-03-21T08:16:23.160898",
     "exception": false,
     "start_time": "2022-03-21T08:16:23.128370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = 'MNIST'\n",
    "seeds = [1, 2, 3]\n",
    "epochs=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f6d7d75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T08:16:23.218563Z",
     "iopub.status.busy": "2022-03-21T08:16:23.217858Z",
     "iopub.status.idle": "2022-03-21T08:16:23.219779Z",
     "shell.execute_reply": "2022-03-21T08:16:23.220174Z",
     "shell.execute_reply.started": "2022-03-21T00:42:28.662214Z"
    },
    "papermill": {
     "duration": 0.032884,
     "end_time": "2022-03-21T08:16:23.220298",
     "exception": false,
     "start_time": "2022-03-21T08:16:23.187414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dataset == 'MNIST':\n",
    "    trainloader = trainloader_MNIST\n",
    "    validloader = validloader_MNIST\n",
    "    testloader = testloader_MNIST\n",
    "\n",
    "    classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n",
    "    \n",
    "    output_size_network = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667e05c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T08:16:23.288567Z",
     "iopub.status.busy": "2022-03-21T08:16:23.287951Z",
     "iopub.status.idle": "2022-03-21T08:16:26.194447Z",
     "shell.execute_reply": "2022-03-21T08:16:26.193908Z",
     "shell.execute_reply.started": "2022-03-21T00:42:28.668937Z"
    },
    "papermill": {
     "duration": 2.946248,
     "end_time": "2022-03-21T08:16:26.194582",
     "exception": false,
     "start_time": "2022-03-21T08:16:23.248334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeNet(Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.AvgPool2d(2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.AvgPool2d(2, stride=2)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.relu1(y)\n",
    "        y = self.pool1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool2(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu3(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.relu4(y)\n",
    "        y = self.fc3(y)\n",
    "        y = self.relu5(y)\n",
    "        return y\n",
    "\n",
    "model1 = LeNet()\n",
    "model1= nn.DataParallel(model1)\n",
    "model1 = model1.to(device)\n",
    "\n",
    "model2 = LeNet()\n",
    "model2= nn.DataParallel(model2)\n",
    "model2 = model2.to(device)\n",
    "\n",
    "model3 = LeNet()\n",
    "model3= nn.DataParallel(model3)\n",
    "model3 = model3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8a09d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T08:16:26.257919Z",
     "iopub.status.busy": "2022-03-21T08:16:26.257380Z",
     "iopub.status.idle": "2022-03-21T08:16:26.842846Z",
     "shell.execute_reply": "2022-03-21T08:16:26.842138Z",
     "shell.execute_reply.started": "2022-03-21T00:42:31.584091Z"
    },
    "papermill": {
     "duration": 0.620578,
     "end_time": "2022-03-21T08:16:26.842982",
     "exception": false,
     "start_time": "2022-03-21T08:16:26.222404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model4 = models.resnet18(pretrained=False)\n",
    "model4.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "num_ftrs = model4.fc.in_features\n",
    "model4.fc = nn.Linear(num_ftrs, output_size_network)\n",
    "model4 = nn.DataParallel(model4)\n",
    "model4 = model4.to(device)\n",
    "\n",
    "model5 = models.resnet18(pretrained=False)\n",
    "model5.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "num_ftrs = model5.fc.in_features\n",
    "model5.fc = nn.Linear(num_ftrs, output_size_network)\n",
    "model5 = nn.DataParallel(model5)\n",
    "model5 = model5.to(device)\n",
    "\n",
    "model6 = models.resnet18(pretrained=False)\n",
    "model6.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "num_ftrs = model6.fc.in_features\n",
    "model6.fc = nn.Linear(num_ftrs, output_size_network)\n",
    "model6 = nn.DataParallel(model6)\n",
    "model6 = model6.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0304867c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T08:16:26.907529Z",
     "iopub.status.busy": "2022-03-21T08:16:26.906653Z",
     "iopub.status.idle": "2022-03-21T08:16:26.915781Z",
     "shell.execute_reply": "2022-03-21T08:16:26.915241Z",
     "shell.execute_reply.started": "2022-03-21T00:42:32.168624Z"
    },
    "papermill": {
     "duration": 0.045859,
     "end_time": "2022-03-21T08:16:26.915911",
     "exception": false,
     "start_time": "2022-03-21T08:16:26.870052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=output_size_network):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model7 = ConvNet()\n",
    "model7 = nn.DataParallel(model7)\n",
    "model7 = model7.to(device)\n",
    "\n",
    "model8 = ConvNet()\n",
    "model8 = nn.DataParallel(model8)\n",
    "model8 = model8.to(device)\n",
    "\n",
    "model9 = ConvNet()\n",
    "model9 = nn.DataParallel(model9)\n",
    "model9 = model9.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4de3611f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T08:16:26.975254Z",
     "iopub.status.busy": "2022-03-21T08:16:26.974325Z",
     "iopub.status.idle": "2022-03-21T08:16:26.976414Z",
     "shell.execute_reply": "2022-03-21T08:16:26.976845Z",
     "shell.execute_reply.started": "2022-03-21T00:42:32.188643Z"
    },
    "papermill": {
     "duration": 0.034254,
     "end_time": "2022-03-21T08:16:26.976964",
     "exception": false,
     "start_time": "2022-03-21T08:16:26.942710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelLeNet = [model1, model2, model3] \n",
    "modelResNet = [model4, model5, model6]\n",
    "modelConvNet = [model7, model8, model9]\n",
    "model = [modelLeNet, modelResNet, modelConvNet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9f8d631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T08:16:27.042953Z",
     "iopub.status.busy": "2022-03-21T08:16:27.042194Z",
     "iopub.status.idle": "2022-03-21T08:16:27.044643Z",
     "shell.execute_reply": "2022-03-21T08:16:27.044201Z",
     "shell.execute_reply.started": "2022-03-21T00:42:32.195306Z"
    },
    "papermill": {
     "duration": 0.040651,
     "end_time": "2022-03-21T08:16:27.044744",
     "exception": false,
     "start_time": "2022-03-21T08:16:27.004093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer1 = optim.SGD(model1.parameters(), lr=0.1)\n",
    "optimizer2 = optim.SGD(model2.parameters(), lr=0.1)\n",
    "optimizer3 = optim.SGD(model3.parameters(), lr=0.1)\n",
    "optimizer4 = optim.SGD(model4.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer5 = optim.SGD(model5.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer6 = optim.SGD(model6.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer7 = optim.SGD(model7.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer8 = optim.SGD(model8.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer9 = optim.SGD(model9.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "optimizer = [[optimizer1, optimizer2, optimizer3], [optimizer4, optimizer5, optimizer6], [optimizer7, optimizer8, optimizer9]]\n",
    "\n",
    "val_loss_min1 = np.Inf\n",
    "val_loss_min2 = np.Inf\n",
    "val_loss_min3 = np.Inf\n",
    "val_loss_min4 = np.Inf\n",
    "val_loss_min5 = np.Inf\n",
    "val_loss_min6 = np.Inf\n",
    "val_loss_min7 = np.Inf\n",
    "val_loss_min8 = np.Inf\n",
    "val_loss_min9 = np.Inf\n",
    "\n",
    "val_loss_min = [[val_loss_min1, val_loss_min2, val_loss_min3], [val_loss_min4, val_loss_min5, val_loss_min6], [val_loss_min7, val_loss_min8, val_loss_min9]]\n",
    "\n",
    "networks = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8afe2c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T08:16:27.115537Z",
     "iopub.status.busy": "2022-03-21T08:16:27.114921Z",
     "iopub.status.idle": "2022-03-21T14:43:07.879994Z",
     "shell.execute_reply": "2022-03-21T14:43:07.880518Z",
     "shell.execute_reply.started": "2022-03-21T00:42:32.213218Z"
    },
    "papermill": {
     "duration": 23200.809723,
     "end_time": "2022-03-21T14:43:07.880711",
     "exception": false,
     "start_time": "2022-03-21T08:16:27.070988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "SEED: 1\n",
      "MODEL: LeNet\n",
      "-------------------\n",
      "Seed: 1 \tEpoch: 1 \tTraining Loss: 0.768 \tValidation Loss: 0.138\n",
      "Validation loss decreased (inf --> 0.138).  Saving model ...\n",
      "Seed: 1 \tEpoch: 2 \tTraining Loss: 0.103 \tValidation Loss: 0.070\n",
      "Validation loss decreased (0.138 --> 0.070).  Saving model ...\n",
      "Seed: 1 \tEpoch: 3 \tTraining Loss: 0.067 \tValidation Loss: 0.074\n",
      "Seed: 1 \tEpoch: 4 \tTraining Loss: 0.052 \tValidation Loss: 0.070\n",
      "Validation loss decreased (0.070 --> 0.070).  Saving model ...\n",
      "Seed: 1 \tEpoch: 5 \tTraining Loss: 0.043 \tValidation Loss: 0.049\n",
      "Validation loss decreased (0.070 --> 0.049).  Saving model ...\n",
      "Seed: 1 \tEpoch: 6 \tTraining Loss: 0.034 \tValidation Loss: 0.056\n",
      "Seed: 1 \tEpoch: 7 \tTraining Loss: 0.029 \tValidation Loss: 0.055\n",
      "Seed: 1 \tEpoch: 8 \tTraining Loss: 0.025 \tValidation Loss: 0.054\n",
      "Seed: 1 \tEpoch: 9 \tTraining Loss: 0.022 \tValidation Loss: 0.059\n",
      "Seed: 1 \tEpoch: 10 \tTraining Loss: 0.019 \tValidation Loss: 0.045\n",
      "Validation loss decreased (0.049 --> 0.045).  Saving model ...\n",
      "Seed: 1 \tEpoch: 11 \tTraining Loss: 0.015 \tValidation Loss: 0.050\n",
      "Seed: 1 \tEpoch: 12 \tTraining Loss: 0.015 \tValidation Loss: 0.076\n",
      "Seed: 1 \tEpoch: 13 \tTraining Loss: 0.013 \tValidation Loss: 0.059\n",
      "Seed: 1 \tEpoch: 14 \tTraining Loss: 0.012 \tValidation Loss: 0.063\n",
      "Seed: 1 \tEpoch: 15 \tTraining Loss: 0.009 \tValidation Loss: 0.056\n",
      "Seed: 1 \tEpoch: 16 \tTraining Loss: 0.009 \tValidation Loss: 0.058\n",
      "Seed: 1 \tEpoch: 17 \tTraining Loss: 0.010 \tValidation Loss: 0.055\n",
      "Seed: 1 \tEpoch: 18 \tTraining Loss: 0.008 \tValidation Loss: 0.061\n",
      "Seed: 1 \tEpoch: 19 \tTraining Loss: 0.005 \tValidation Loss: 0.050\n",
      "Seed: 1 \tEpoch: 20 \tTraining Loss: 0.006 \tValidation Loss: 0.056\n",
      "Seed: 1 \tEpoch: 21 \tTraining Loss: 0.005 \tValidation Loss: 0.069\n",
      "Seed: 1 \tEpoch: 22 \tTraining Loss: 0.006 \tValidation Loss: 0.058\n",
      "Seed: 1 \tEpoch: 23 \tTraining Loss: 0.002 \tValidation Loss: 0.057\n",
      "Seed: 1 \tEpoch: 24 \tTraining Loss: 0.002 \tValidation Loss: 0.060\n",
      "Seed: 1 \tEpoch: 25 \tTraining Loss: 0.001 \tValidation Loss: 0.062\n",
      "Seed: 1 \tEpoch: 26 \tTraining Loss: 0.001 \tValidation Loss: 0.060\n",
      "Seed: 1 \tEpoch: 27 \tTraining Loss: 0.000 \tValidation Loss: 0.063\n",
      "Seed: 1 \tEpoch: 28 \tTraining Loss: 0.000 \tValidation Loss: 0.065\n",
      "Seed: 1 \tEpoch: 29 \tTraining Loss: 0.000 \tValidation Loss: 0.066\n",
      "Seed: 1 \tEpoch: 30 \tTraining Loss: 0.000 \tValidation Loss: 0.067\n",
      "Seed: 1 \tEpoch: 31 \tTraining Loss: 0.000 \tValidation Loss: 0.070\n",
      "Seed: 1 \tEpoch: 32 \tTraining Loss: 0.000 \tValidation Loss: 0.069\n",
      "Seed: 1 \tEpoch: 33 \tTraining Loss: 0.000 \tValidation Loss: 0.070\n",
      "Seed: 1 \tEpoch: 34 \tTraining Loss: 0.000 \tValidation Loss: 0.071\n",
      "Seed: 1 \tEpoch: 35 \tTraining Loss: 0.000 \tValidation Loss: 0.072\n",
      "Seed: 1 \tEpoch: 36 \tTraining Loss: 0.000 \tValidation Loss: 0.072\n",
      "Seed: 1 \tEpoch: 37 \tTraining Loss: 0.000 \tValidation Loss: 0.073\n",
      "Seed: 1 \tEpoch: 38 \tTraining Loss: 0.000 \tValidation Loss: 0.074\n",
      "Seed: 1 \tEpoch: 39 \tTraining Loss: 0.000 \tValidation Loss: 0.075\n",
      "Seed: 1 \tEpoch: 40 \tTraining Loss: 0.000 \tValidation Loss: 0.075\n",
      "Seed: 1 \tEpoch: 41 \tTraining Loss: 0.000 \tValidation Loss: 0.075\n",
      "Seed: 1 \tEpoch: 42 \tTraining Loss: 0.000 \tValidation Loss: 0.076\n",
      "Seed: 1 \tEpoch: 43 \tTraining Loss: 0.000 \tValidation Loss: 0.077\n",
      "Seed: 1 \tEpoch: 44 \tTraining Loss: 0.000 \tValidation Loss: 0.078\n",
      "Seed: 1 \tEpoch: 45 \tTraining Loss: 0.000 \tValidation Loss: 0.078\n",
      "Seed: 1 \tEpoch: 46 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 1 \tEpoch: 47 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 1 \tEpoch: 48 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 1 \tEpoch: 49 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 1 \tEpoch: 50 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 1 \tEpoch: 51 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 1 \tEpoch: 52 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 1 \tEpoch: 53 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 1 \tEpoch: 54 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 1 \tEpoch: 55 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 1 \tEpoch: 56 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 1 \tEpoch: 57 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 1 \tEpoch: 58 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 1 \tEpoch: 59 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 1 \tEpoch: 60 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 1 \tEpoch: 61 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 1 \tEpoch: 62 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 1 \tEpoch: 63 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 1 \tEpoch: 64 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 1 \tEpoch: 65 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 1 \tEpoch: 66 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 1 \tEpoch: 67 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 1 \tEpoch: 68 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 1 \tEpoch: 69 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 1 \tEpoch: 70 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 1 \tEpoch: 71 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 1 \tEpoch: 72 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 1 \tEpoch: 73 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 1 \tEpoch: 74 \tTraining Loss: 0.000 \tValidation Loss: 0.087\n",
      "Seed: 1 \tEpoch: 75 \tTraining Loss: 0.000 \tValidation Loss: 0.087\n",
      "Seed: 1 \tEpoch: 76 \tTraining Loss: 0.000 \tValidation Loss: 0.087\n",
      "Seed: 1 \tEpoch: 77 \tTraining Loss: 0.000 \tValidation Loss: 0.087\n",
      "Seed: 1 \tEpoch: 78 \tTraining Loss: 0.000 \tValidation Loss: 0.087\n",
      "Seed: 1 \tEpoch: 79 \tTraining Loss: 0.000 \tValidation Loss: 0.088\n",
      "Seed: 1 \tEpoch: 80 \tTraining Loss: 0.000 \tValidation Loss: 0.088\n",
      "Seed: 1 \tEpoch: 81 \tTraining Loss: 0.000 \tValidation Loss: 0.088\n",
      "Seed: 1 \tEpoch: 82 \tTraining Loss: 0.000 \tValidation Loss: 0.088\n",
      "Seed: 1 \tEpoch: 83 \tTraining Loss: 0.000 \tValidation Loss: 0.088\n",
      "Seed: 1 \tEpoch: 84 \tTraining Loss: 0.000 \tValidation Loss: 0.088\n",
      "Seed: 1 \tEpoch: 85 \tTraining Loss: 0.000 \tValidation Loss: 0.089\n",
      "Seed: 1 \tEpoch: 86 \tTraining Loss: 0.000 \tValidation Loss: 0.089\n",
      "Seed: 1 \tEpoch: 87 \tTraining Loss: 0.000 \tValidation Loss: 0.089\n",
      "Seed: 1 \tEpoch: 88 \tTraining Loss: 0.000 \tValidation Loss: 0.089\n",
      "Seed: 1 \tEpoch: 89 \tTraining Loss: 0.000 \tValidation Loss: 0.089\n",
      "Seed: 1 \tEpoch: 90 \tTraining Loss: 0.000 \tValidation Loss: 0.089\n",
      "Seed: 1 \tEpoch: 91 \tTraining Loss: 0.000 \tValidation Loss: 0.089\n",
      "Seed: 1 \tEpoch: 92 \tTraining Loss: 0.000 \tValidation Loss: 0.090\n",
      "Seed: 1 \tEpoch: 93 \tTraining Loss: 0.000 \tValidation Loss: 0.090\n",
      "Seed: 1 \tEpoch: 94 \tTraining Loss: 0.000 \tValidation Loss: 0.090\n",
      "Seed: 1 \tEpoch: 95 \tTraining Loss: 0.000 \tValidation Loss: 0.090\n",
      "Seed: 1 \tEpoch: 96 \tTraining Loss: 0.000 \tValidation Loss: 0.091\n",
      "Seed: 1 \tEpoch: 97 \tTraining Loss: 0.000 \tValidation Loss: 0.090\n",
      "Seed: 1 \tEpoch: 98 \tTraining Loss: 0.000 \tValidation Loss: 0.090\n",
      "Seed: 1 \tEpoch: 99 \tTraining Loss: 0.000 \tValidation Loss: 0.091\n",
      "Seed: 1 \tEpoch: 100 \tTraining Loss: 0.000 \tValidation Loss: 0.091\n",
      "Seed: 1 \tEpoch: 101 \tTraining Loss: 0.000 \tValidation Loss: 0.091\n",
      "Seed: 1 \tEpoch: 102 \tTraining Loss: 0.000 \tValidation Loss: 0.092\n",
      "Seed: 1 \tEpoch: 103 \tTraining Loss: 0.000 \tValidation Loss: 0.091\n",
      "Seed: 1 \tEpoch: 104 \tTraining Loss: 0.000 \tValidation Loss: 0.091\n",
      "Seed: 1 \tEpoch: 105 \tTraining Loss: 0.000 \tValidation Loss: 0.091\n",
      "Seed: 1 \tEpoch: 106 \tTraining Loss: 0.000 \tValidation Loss: 0.091\n",
      "Seed: 1 \tEpoch: 107 \tTraining Loss: 0.000 \tValidation Loss: 0.092\n",
      "Seed: 1 \tEpoch: 108 \tTraining Loss: 0.000 \tValidation Loss: 0.092\n",
      "Seed: 1 \tEpoch: 109 \tTraining Loss: 0.000 \tValidation Loss: 0.092\n",
      "Seed: 1 \tEpoch: 110 \tTraining Loss: 0.000 \tValidation Loss: 0.092\n",
      "Seed: 1 \tEpoch: 111 \tTraining Loss: 0.000 \tValidation Loss: 0.092\n",
      "Seed: 1 \tEpoch: 112 \tTraining Loss: 0.000 \tValidation Loss: 0.092\n",
      "Seed: 1 \tEpoch: 113 \tTraining Loss: 0.000 \tValidation Loss: 0.092\n",
      "Seed: 1 \tEpoch: 114 \tTraining Loss: 0.000 \tValidation Loss: 0.092\n",
      "Seed: 1 \tEpoch: 115 \tTraining Loss: 0.000 \tValidation Loss: 0.092\n",
      "Seed: 1 \tEpoch: 116 \tTraining Loss: 0.000 \tValidation Loss: 0.093\n",
      "Seed: 1 \tEpoch: 117 \tTraining Loss: 0.000 \tValidation Loss: 0.093\n",
      "Seed: 1 \tEpoch: 118 \tTraining Loss: 0.000 \tValidation Loss: 0.093\n",
      "Seed: 1 \tEpoch: 119 \tTraining Loss: 0.000 \tValidation Loss: 0.093\n",
      "Seed: 1 \tEpoch: 120 \tTraining Loss: 0.000 \tValidation Loss: 0.093\n",
      "Seed: 1 \tEpoch: 121 \tTraining Loss: 0.000 \tValidation Loss: 0.094\n",
      "Seed: 1 \tEpoch: 122 \tTraining Loss: 0.000 \tValidation Loss: 0.093\n",
      "Seed: 1 \tEpoch: 123 \tTraining Loss: 0.000 \tValidation Loss: 0.093\n",
      "Seed: 1 \tEpoch: 124 \tTraining Loss: 0.000 \tValidation Loss: 0.093\n",
      "Seed: 1 \tEpoch: 125 \tTraining Loss: 0.000 \tValidation Loss: 0.094\n",
      "Seed: 1 \tEpoch: 126 \tTraining Loss: 0.000 \tValidation Loss: 0.094\n",
      "Seed: 1 \tEpoch: 127 \tTraining Loss: 0.000 \tValidation Loss: 0.094\n",
      "Seed: 1 \tEpoch: 128 \tTraining Loss: 0.000 \tValidation Loss: 0.094\n",
      "Seed: 1 \tEpoch: 129 \tTraining Loss: 0.000 \tValidation Loss: 0.094\n",
      "Seed: 1 \tEpoch: 130 \tTraining Loss: 0.000 \tValidation Loss: 0.094\n",
      "Seed: 1 \tEpoch: 131 \tTraining Loss: 0.000 \tValidation Loss: 0.094\n",
      "Seed: 1 \tEpoch: 132 \tTraining Loss: 0.000 \tValidation Loss: 0.094\n",
      "Seed: 1 \tEpoch: 133 \tTraining Loss: 0.000 \tValidation Loss: 0.094\n",
      "Seed: 1 \tEpoch: 134 \tTraining Loss: 0.000 \tValidation Loss: 0.094\n",
      "Seed: 1 \tEpoch: 135 \tTraining Loss: 0.000 \tValidation Loss: 0.095\n",
      "Seed: 1 \tEpoch: 136 \tTraining Loss: 0.000 \tValidation Loss: 0.095\n",
      "Seed: 1 \tEpoch: 137 \tTraining Loss: 0.000 \tValidation Loss: 0.095\n",
      "Seed: 1 \tEpoch: 138 \tTraining Loss: 0.000 \tValidation Loss: 0.095\n",
      "Seed: 1 \tEpoch: 139 \tTraining Loss: 0.000 \tValidation Loss: 0.095\n",
      "Seed: 1 \tEpoch: 140 \tTraining Loss: 0.000 \tValidation Loss: 0.095\n",
      "Seed: 1 \tEpoch: 141 \tTraining Loss: 0.000 \tValidation Loss: 0.095\n",
      "Seed: 1 \tEpoch: 142 \tTraining Loss: 0.000 \tValidation Loss: 0.095\n",
      "Seed: 1 \tEpoch: 143 \tTraining Loss: 0.000 \tValidation Loss: 0.095\n",
      "Seed: 1 \tEpoch: 144 \tTraining Loss: 0.000 \tValidation Loss: 0.095\n",
      "Seed: 1 \tEpoch: 145 \tTraining Loss: 0.000 \tValidation Loss: 0.095\n",
      "Seed: 1 \tEpoch: 146 \tTraining Loss: 0.000 \tValidation Loss: 0.096\n",
      "Seed: 1 \tEpoch: 147 \tTraining Loss: 0.000 \tValidation Loss: 0.096\n",
      "Seed: 1 \tEpoch: 148 \tTraining Loss: 0.000 \tValidation Loss: 0.096\n",
      "Seed: 1 \tEpoch: 149 \tTraining Loss: 0.000 \tValidation Loss: 0.096\n",
      "Seed: 1 \tEpoch: 150 \tTraining Loss: 0.000 \tValidation Loss: 0.096\n",
      "Finished Training for seed 1 of model LeNet\n",
      "-------------------\n",
      "SEED: 2\n",
      "MODEL: LeNet\n",
      "-------------------\n",
      "Seed: 2 \tEpoch: 1 \tTraining Loss: 0.612 \tValidation Loss: 0.122\n",
      "Validation loss decreased (inf --> 0.122).  Saving model ...\n",
      "Seed: 2 \tEpoch: 2 \tTraining Loss: 0.096 \tValidation Loss: 0.079\n",
      "Validation loss decreased (0.122 --> 0.079).  Saving model ...\n",
      "Seed: 2 \tEpoch: 3 \tTraining Loss: 0.064 \tValidation Loss: 0.056\n",
      "Validation loss decreased (0.079 --> 0.056).  Saving model ...\n",
      "Seed: 2 \tEpoch: 4 \tTraining Loss: 0.048 \tValidation Loss: 0.059\n",
      "Seed: 2 \tEpoch: 5 \tTraining Loss: 0.040 \tValidation Loss: 0.046\n",
      "Validation loss decreased (0.056 --> 0.046).  Saving model ...\n",
      "Seed: 2 \tEpoch: 6 \tTraining Loss: 0.032 \tValidation Loss: 0.056\n",
      "Seed: 2 \tEpoch: 7 \tTraining Loss: 0.028 \tValidation Loss: 0.068\n",
      "Seed: 2 \tEpoch: 8 \tTraining Loss: 0.025 \tValidation Loss: 0.056\n",
      "Seed: 2 \tEpoch: 9 \tTraining Loss: 0.020 \tValidation Loss: 0.049\n",
      "Seed: 2 \tEpoch: 10 \tTraining Loss: 0.017 \tValidation Loss: 0.060\n",
      "Seed: 2 \tEpoch: 11 \tTraining Loss: 0.014 \tValidation Loss: 0.051\n",
      "Seed: 2 \tEpoch: 12 \tTraining Loss: 0.014 \tValidation Loss: 0.045\n",
      "Validation loss decreased (0.046 --> 0.045).  Saving model ...\n",
      "Seed: 2 \tEpoch: 13 \tTraining Loss: 0.012 \tValidation Loss: 0.053\n",
      "Seed: 2 \tEpoch: 14 \tTraining Loss: 0.009 \tValidation Loss: 0.051\n",
      "Seed: 2 \tEpoch: 15 \tTraining Loss: 0.008 \tValidation Loss: 0.053\n",
      "Seed: 2 \tEpoch: 16 \tTraining Loss: 0.010 \tValidation Loss: 0.048\n",
      "Seed: 2 \tEpoch: 17 \tTraining Loss: 0.009 \tValidation Loss: 0.062\n",
      "Seed: 2 \tEpoch: 18 \tTraining Loss: 0.005 \tValidation Loss: 0.052\n",
      "Seed: 2 \tEpoch: 19 \tTraining Loss: 0.007 \tValidation Loss: 0.047\n",
      "Seed: 2 \tEpoch: 20 \tTraining Loss: 0.006 \tValidation Loss: 0.077\n",
      "Seed: 2 \tEpoch: 21 \tTraining Loss: 0.004 \tValidation Loss: 0.057\n",
      "Seed: 2 \tEpoch: 22 \tTraining Loss: 0.003 \tValidation Loss: 0.059\n",
      "Seed: 2 \tEpoch: 23 \tTraining Loss: 0.003 \tValidation Loss: 0.057\n",
      "Seed: 2 \tEpoch: 24 \tTraining Loss: 0.004 \tValidation Loss: 0.062\n",
      "Seed: 2 \tEpoch: 25 \tTraining Loss: 0.003 \tValidation Loss: 0.067\n",
      "Seed: 2 \tEpoch: 26 \tTraining Loss: 0.006 \tValidation Loss: 0.057\n",
      "Seed: 2 \tEpoch: 27 \tTraining Loss: 0.003 \tValidation Loss: 0.062\n",
      "Seed: 2 \tEpoch: 28 \tTraining Loss: 0.003 \tValidation Loss: 0.057\n",
      "Seed: 2 \tEpoch: 29 \tTraining Loss: 0.002 \tValidation Loss: 0.070\n",
      "Seed: 2 \tEpoch: 30 \tTraining Loss: 0.001 \tValidation Loss: 0.059\n",
      "Seed: 2 \tEpoch: 31 \tTraining Loss: 0.001 \tValidation Loss: 0.057\n",
      "Seed: 2 \tEpoch: 32 \tTraining Loss: 0.000 \tValidation Loss: 0.060\n",
      "Seed: 2 \tEpoch: 33 \tTraining Loss: 0.000 \tValidation Loss: 0.061\n",
      "Seed: 2 \tEpoch: 34 \tTraining Loss: 0.000 \tValidation Loss: 0.062\n",
      "Seed: 2 \tEpoch: 35 \tTraining Loss: 0.000 \tValidation Loss: 0.063\n",
      "Seed: 2 \tEpoch: 36 \tTraining Loss: 0.000 \tValidation Loss: 0.064\n",
      "Seed: 2 \tEpoch: 37 \tTraining Loss: 0.000 \tValidation Loss: 0.065\n",
      "Seed: 2 \tEpoch: 38 \tTraining Loss: 0.000 \tValidation Loss: 0.066\n",
      "Seed: 2 \tEpoch: 39 \tTraining Loss: 0.000 \tValidation Loss: 0.067\n",
      "Seed: 2 \tEpoch: 40 \tTraining Loss: 0.000 \tValidation Loss: 0.067\n",
      "Seed: 2 \tEpoch: 41 \tTraining Loss: 0.000 \tValidation Loss: 0.068\n",
      "Seed: 2 \tEpoch: 42 \tTraining Loss: 0.000 \tValidation Loss: 0.068\n",
      "Seed: 2 \tEpoch: 43 \tTraining Loss: 0.000 \tValidation Loss: 0.069\n",
      "Seed: 2 \tEpoch: 44 \tTraining Loss: 0.000 \tValidation Loss: 0.069\n",
      "Seed: 2 \tEpoch: 45 \tTraining Loss: 0.000 \tValidation Loss: 0.070\n",
      "Seed: 2 \tEpoch: 46 \tTraining Loss: 0.000 \tValidation Loss: 0.070\n",
      "Seed: 2 \tEpoch: 47 \tTraining Loss: 0.000 \tValidation Loss: 0.070\n",
      "Seed: 2 \tEpoch: 48 \tTraining Loss: 0.000 \tValidation Loss: 0.072\n",
      "Seed: 2 \tEpoch: 49 \tTraining Loss: 0.000 \tValidation Loss: 0.071\n",
      "Seed: 2 \tEpoch: 50 \tTraining Loss: 0.000 \tValidation Loss: 0.072\n",
      "Seed: 2 \tEpoch: 51 \tTraining Loss: 0.000 \tValidation Loss: 0.072\n",
      "Seed: 2 \tEpoch: 52 \tTraining Loss: 0.000 \tValidation Loss: 0.072\n",
      "Seed: 2 \tEpoch: 53 \tTraining Loss: 0.000 \tValidation Loss: 0.073\n",
      "Seed: 2 \tEpoch: 54 \tTraining Loss: 0.000 \tValidation Loss: 0.073\n",
      "Seed: 2 \tEpoch: 55 \tTraining Loss: 0.000 \tValidation Loss: 0.073\n",
      "Seed: 2 \tEpoch: 56 \tTraining Loss: 0.000 \tValidation Loss: 0.073\n",
      "Seed: 2 \tEpoch: 57 \tTraining Loss: 0.000 \tValidation Loss: 0.074\n",
      "Seed: 2 \tEpoch: 58 \tTraining Loss: 0.000 \tValidation Loss: 0.074\n",
      "Seed: 2 \tEpoch: 59 \tTraining Loss: 0.000 \tValidation Loss: 0.074\n",
      "Seed: 2 \tEpoch: 60 \tTraining Loss: 0.000 \tValidation Loss: 0.074\n",
      "Seed: 2 \tEpoch: 61 \tTraining Loss: 0.000 \tValidation Loss: 0.075\n",
      "Seed: 2 \tEpoch: 62 \tTraining Loss: 0.000 \tValidation Loss: 0.075\n",
      "Seed: 2 \tEpoch: 63 \tTraining Loss: 0.000 \tValidation Loss: 0.075\n",
      "Seed: 2 \tEpoch: 64 \tTraining Loss: 0.000 \tValidation Loss: 0.076\n",
      "Seed: 2 \tEpoch: 65 \tTraining Loss: 0.000 \tValidation Loss: 0.076\n",
      "Seed: 2 \tEpoch: 66 \tTraining Loss: 0.000 \tValidation Loss: 0.076\n",
      "Seed: 2 \tEpoch: 67 \tTraining Loss: 0.000 \tValidation Loss: 0.076\n",
      "Seed: 2 \tEpoch: 68 \tTraining Loss: 0.000 \tValidation Loss: 0.076\n",
      "Seed: 2 \tEpoch: 69 \tTraining Loss: 0.000 \tValidation Loss: 0.076\n",
      "Seed: 2 \tEpoch: 70 \tTraining Loss: 0.000 \tValidation Loss: 0.077\n",
      "Seed: 2 \tEpoch: 71 \tTraining Loss: 0.000 \tValidation Loss: 0.077\n",
      "Seed: 2 \tEpoch: 72 \tTraining Loss: 0.000 \tValidation Loss: 0.077\n",
      "Seed: 2 \tEpoch: 73 \tTraining Loss: 0.000 \tValidation Loss: 0.077\n",
      "Seed: 2 \tEpoch: 74 \tTraining Loss: 0.000 \tValidation Loss: 0.077\n",
      "Seed: 2 \tEpoch: 75 \tTraining Loss: 0.000 \tValidation Loss: 0.078\n",
      "Seed: 2 \tEpoch: 76 \tTraining Loss: 0.000 \tValidation Loss: 0.078\n",
      "Seed: 2 \tEpoch: 77 \tTraining Loss: 0.000 \tValidation Loss: 0.078\n",
      "Seed: 2 \tEpoch: 78 \tTraining Loss: 0.000 \tValidation Loss: 0.078\n",
      "Seed: 2 \tEpoch: 79 \tTraining Loss: 0.000 \tValidation Loss: 0.078\n",
      "Seed: 2 \tEpoch: 80 \tTraining Loss: 0.000 \tValidation Loss: 0.078\n",
      "Seed: 2 \tEpoch: 81 \tTraining Loss: 0.000 \tValidation Loss: 0.078\n",
      "Seed: 2 \tEpoch: 82 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 2 \tEpoch: 83 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 2 \tEpoch: 84 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 2 \tEpoch: 85 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 2 \tEpoch: 86 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 2 \tEpoch: 87 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 2 \tEpoch: 88 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 2 \tEpoch: 89 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 2 \tEpoch: 90 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 2 \tEpoch: 91 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 2 \tEpoch: 92 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 2 \tEpoch: 93 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 2 \tEpoch: 94 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 2 \tEpoch: 95 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 2 \tEpoch: 96 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 2 \tEpoch: 97 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 2 \tEpoch: 98 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 2 \tEpoch: 99 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 2 \tEpoch: 100 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 2 \tEpoch: 101 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 2 \tEpoch: 102 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 2 \tEpoch: 103 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 2 \tEpoch: 104 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 2 \tEpoch: 105 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 2 \tEpoch: 106 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 2 \tEpoch: 107 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 2 \tEpoch: 108 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 2 \tEpoch: 109 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 2 \tEpoch: 110 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 2 \tEpoch: 111 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 2 \tEpoch: 112 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 2 \tEpoch: 113 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 2 \tEpoch: 114 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 2 \tEpoch: 115 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 2 \tEpoch: 116 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 2 \tEpoch: 117 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 2 \tEpoch: 118 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 2 \tEpoch: 119 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 2 \tEpoch: 120 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 2 \tEpoch: 121 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 2 \tEpoch: 122 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 2 \tEpoch: 123 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 2 \tEpoch: 124 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 2 \tEpoch: 125 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 2 \tEpoch: 126 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 2 \tEpoch: 127 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 2 \tEpoch: 128 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 2 \tEpoch: 129 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 2 \tEpoch: 130 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 2 \tEpoch: 131 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 2 \tEpoch: 132 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 2 \tEpoch: 133 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 2 \tEpoch: 134 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 2 \tEpoch: 135 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 2 \tEpoch: 136 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 2 \tEpoch: 137 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 2 \tEpoch: 138 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 2 \tEpoch: 139 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 2 \tEpoch: 140 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 2 \tEpoch: 141 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 2 \tEpoch: 142 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 2 \tEpoch: 143 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 2 \tEpoch: 144 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 2 \tEpoch: 145 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 2 \tEpoch: 146 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 2 \tEpoch: 147 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 2 \tEpoch: 148 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 2 \tEpoch: 149 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 2 \tEpoch: 150 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Finished Training for seed 2 of model LeNet\n",
      "-------------------\n",
      "SEED: 3\n",
      "MODEL: LeNet\n",
      "-------------------\n",
      "Seed: 3 \tEpoch: 1 \tTraining Loss: 0.493 \tValidation Loss: 0.099\n",
      "Validation loss decreased (inf --> 0.099).  Saving model ...\n",
      "Seed: 3 \tEpoch: 2 \tTraining Loss: 0.085 \tValidation Loss: 0.075\n",
      "Validation loss decreased (0.099 --> 0.075).  Saving model ...\n",
      "Seed: 3 \tEpoch: 3 \tTraining Loss: 0.060 \tValidation Loss: 0.061\n",
      "Validation loss decreased (0.075 --> 0.061).  Saving model ...\n",
      "Seed: 3 \tEpoch: 4 \tTraining Loss: 0.046 \tValidation Loss: 0.050\n",
      "Validation loss decreased (0.061 --> 0.050).  Saving model ...\n",
      "Seed: 3 \tEpoch: 5 \tTraining Loss: 0.038 \tValidation Loss: 0.047\n",
      "Validation loss decreased (0.050 --> 0.047).  Saving model ...\n",
      "Seed: 3 \tEpoch: 6 \tTraining Loss: 0.031 \tValidation Loss: 0.048\n",
      "Seed: 3 \tEpoch: 7 \tTraining Loss: 0.026 \tValidation Loss: 0.046\n",
      "Validation loss decreased (0.047 --> 0.046).  Saving model ...\n",
      "Seed: 3 \tEpoch: 8 \tTraining Loss: 0.023 \tValidation Loss: 0.044\n",
      "Validation loss decreased (0.046 --> 0.044).  Saving model ...\n",
      "Seed: 3 \tEpoch: 9 \tTraining Loss: 0.021 \tValidation Loss: 0.041\n",
      "Validation loss decreased (0.044 --> 0.041).  Saving model ...\n",
      "Seed: 3 \tEpoch: 10 \tTraining Loss: 0.017 \tValidation Loss: 0.052\n",
      "Seed: 3 \tEpoch: 11 \tTraining Loss: 0.016 \tValidation Loss: 0.051\n",
      "Seed: 3 \tEpoch: 12 \tTraining Loss: 0.013 \tValidation Loss: 0.042\n",
      "Seed: 3 \tEpoch: 13 \tTraining Loss: 0.013 \tValidation Loss: 0.051\n",
      "Seed: 3 \tEpoch: 14 \tTraining Loss: 0.011 \tValidation Loss: 0.046\n",
      "Seed: 3 \tEpoch: 15 \tTraining Loss: 0.011 \tValidation Loss: 0.048\n",
      "Seed: 3 \tEpoch: 16 \tTraining Loss: 0.008 \tValidation Loss: 0.060\n",
      "Seed: 3 \tEpoch: 17 \tTraining Loss: 0.007 \tValidation Loss: 0.077\n",
      "Seed: 3 \tEpoch: 18 \tTraining Loss: 0.006 \tValidation Loss: 0.049\n",
      "Seed: 3 \tEpoch: 19 \tTraining Loss: 0.005 \tValidation Loss: 0.055\n",
      "Seed: 3 \tEpoch: 20 \tTraining Loss: 0.007 \tValidation Loss: 0.046\n",
      "Seed: 3 \tEpoch: 21 \tTraining Loss: 0.005 \tValidation Loss: 0.055\n",
      "Seed: 3 \tEpoch: 22 \tTraining Loss: 0.005 \tValidation Loss: 0.052\n",
      "Seed: 3 \tEpoch: 23 \tTraining Loss: 0.005 \tValidation Loss: 0.063\n",
      "Seed: 3 \tEpoch: 24 \tTraining Loss: 0.003 \tValidation Loss: 0.055\n",
      "Seed: 3 \tEpoch: 25 \tTraining Loss: 0.003 \tValidation Loss: 0.058\n",
      "Seed: 3 \tEpoch: 26 \tTraining Loss: 0.002 \tValidation Loss: 0.057\n",
      "Seed: 3 \tEpoch: 27 \tTraining Loss: 0.003 \tValidation Loss: 0.066\n",
      "Seed: 3 \tEpoch: 28 \tTraining Loss: 0.006 \tValidation Loss: 0.084\n",
      "Seed: 3 \tEpoch: 29 \tTraining Loss: 0.007 \tValidation Loss: 0.068\n",
      "Seed: 3 \tEpoch: 30 \tTraining Loss: 0.006 \tValidation Loss: 0.062\n",
      "Seed: 3 \tEpoch: 31 \tTraining Loss: 0.002 \tValidation Loss: 0.067\n",
      "Seed: 3 \tEpoch: 32 \tTraining Loss: 0.003 \tValidation Loss: 0.060\n",
      "Seed: 3 \tEpoch: 33 \tTraining Loss: 0.002 \tValidation Loss: 0.060\n",
      "Seed: 3 \tEpoch: 34 \tTraining Loss: 0.000 \tValidation Loss: 0.062\n",
      "Seed: 3 \tEpoch: 35 \tTraining Loss: 0.000 \tValidation Loss: 0.062\n",
      "Seed: 3 \tEpoch: 36 \tTraining Loss: 0.000 \tValidation Loss: 0.063\n",
      "Seed: 3 \tEpoch: 37 \tTraining Loss: 0.000 \tValidation Loss: 0.064\n",
      "Seed: 3 \tEpoch: 38 \tTraining Loss: 0.000 \tValidation Loss: 0.065\n",
      "Seed: 3 \tEpoch: 39 \tTraining Loss: 0.000 \tValidation Loss: 0.066\n",
      "Seed: 3 \tEpoch: 40 \tTraining Loss: 0.000 \tValidation Loss: 0.067\n",
      "Seed: 3 \tEpoch: 41 \tTraining Loss: 0.000 \tValidation Loss: 0.067\n",
      "Seed: 3 \tEpoch: 42 \tTraining Loss: 0.000 \tValidation Loss: 0.068\n",
      "Seed: 3 \tEpoch: 43 \tTraining Loss: 0.000 \tValidation Loss: 0.069\n",
      "Seed: 3 \tEpoch: 44 \tTraining Loss: 0.000 \tValidation Loss: 0.069\n",
      "Seed: 3 \tEpoch: 45 \tTraining Loss: 0.000 \tValidation Loss: 0.070\n",
      "Seed: 3 \tEpoch: 46 \tTraining Loss: 0.000 \tValidation Loss: 0.070\n",
      "Seed: 3 \tEpoch: 47 \tTraining Loss: 0.000 \tValidation Loss: 0.071\n",
      "Seed: 3 \tEpoch: 48 \tTraining Loss: 0.000 \tValidation Loss: 0.071\n",
      "Seed: 3 \tEpoch: 49 \tTraining Loss: 0.000 \tValidation Loss: 0.072\n",
      "Seed: 3 \tEpoch: 50 \tTraining Loss: 0.000 \tValidation Loss: 0.072\n",
      "Seed: 3 \tEpoch: 51 \tTraining Loss: 0.000 \tValidation Loss: 0.072\n",
      "Seed: 3 \tEpoch: 52 \tTraining Loss: 0.000 \tValidation Loss: 0.073\n",
      "Seed: 3 \tEpoch: 53 \tTraining Loss: 0.000 \tValidation Loss: 0.073\n",
      "Seed: 3 \tEpoch: 54 \tTraining Loss: 0.000 \tValidation Loss: 0.073\n",
      "Seed: 3 \tEpoch: 55 \tTraining Loss: 0.000 \tValidation Loss: 0.074\n",
      "Seed: 3 \tEpoch: 56 \tTraining Loss: 0.000 \tValidation Loss: 0.074\n",
      "Seed: 3 \tEpoch: 57 \tTraining Loss: 0.000 \tValidation Loss: 0.074\n",
      "Seed: 3 \tEpoch: 58 \tTraining Loss: 0.000 \tValidation Loss: 0.074\n",
      "Seed: 3 \tEpoch: 59 \tTraining Loss: 0.000 \tValidation Loss: 0.075\n",
      "Seed: 3 \tEpoch: 60 \tTraining Loss: 0.000 \tValidation Loss: 0.075\n",
      "Seed: 3 \tEpoch: 61 \tTraining Loss: 0.000 \tValidation Loss: 0.075\n",
      "Seed: 3 \tEpoch: 62 \tTraining Loss: 0.000 \tValidation Loss: 0.076\n",
      "Seed: 3 \tEpoch: 63 \tTraining Loss: 0.000 \tValidation Loss: 0.076\n",
      "Seed: 3 \tEpoch: 64 \tTraining Loss: 0.000 \tValidation Loss: 0.076\n",
      "Seed: 3 \tEpoch: 65 \tTraining Loss: 0.000 \tValidation Loss: 0.076\n",
      "Seed: 3 \tEpoch: 66 \tTraining Loss: 0.000 \tValidation Loss: 0.077\n",
      "Seed: 3 \tEpoch: 67 \tTraining Loss: 0.000 \tValidation Loss: 0.077\n",
      "Seed: 3 \tEpoch: 68 \tTraining Loss: 0.000 \tValidation Loss: 0.077\n",
      "Seed: 3 \tEpoch: 69 \tTraining Loss: 0.000 \tValidation Loss: 0.077\n",
      "Seed: 3 \tEpoch: 70 \tTraining Loss: 0.000 \tValidation Loss: 0.077\n",
      "Seed: 3 \tEpoch: 71 \tTraining Loss: 0.000 \tValidation Loss: 0.078\n",
      "Seed: 3 \tEpoch: 72 \tTraining Loss: 0.000 \tValidation Loss: 0.078\n",
      "Seed: 3 \tEpoch: 73 \tTraining Loss: 0.000 \tValidation Loss: 0.078\n",
      "Seed: 3 \tEpoch: 74 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 3 \tEpoch: 75 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 3 \tEpoch: 76 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 3 \tEpoch: 77 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 3 \tEpoch: 78 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 3 \tEpoch: 79 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 3 \tEpoch: 80 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 3 \tEpoch: 81 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 3 \tEpoch: 82 \tTraining Loss: 0.000 \tValidation Loss: 0.079\n",
      "Seed: 3 \tEpoch: 83 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 3 \tEpoch: 84 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 3 \tEpoch: 85 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 3 \tEpoch: 86 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 3 \tEpoch: 87 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 3 \tEpoch: 88 \tTraining Loss: 0.000 \tValidation Loss: 0.080\n",
      "Seed: 3 \tEpoch: 89 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 3 \tEpoch: 90 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 3 \tEpoch: 91 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 3 \tEpoch: 92 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 3 \tEpoch: 93 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 3 \tEpoch: 94 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 3 \tEpoch: 95 \tTraining Loss: 0.000 \tValidation Loss: 0.081\n",
      "Seed: 3 \tEpoch: 96 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 3 \tEpoch: 97 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 3 \tEpoch: 98 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 3 \tEpoch: 99 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 3 \tEpoch: 100 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 3 \tEpoch: 101 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 3 \tEpoch: 102 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 3 \tEpoch: 103 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 3 \tEpoch: 104 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 3 \tEpoch: 105 \tTraining Loss: 0.000 \tValidation Loss: 0.082\n",
      "Seed: 3 \tEpoch: 106 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 3 \tEpoch: 107 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 3 \tEpoch: 108 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 3 \tEpoch: 109 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 3 \tEpoch: 110 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 3 \tEpoch: 111 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 3 \tEpoch: 112 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 3 \tEpoch: 113 \tTraining Loss: 0.000 \tValidation Loss: 0.083\n",
      "Seed: 3 \tEpoch: 114 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 3 \tEpoch: 115 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 3 \tEpoch: 116 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 3 \tEpoch: 117 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 3 \tEpoch: 118 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 3 \tEpoch: 119 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 3 \tEpoch: 120 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 3 \tEpoch: 121 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 3 \tEpoch: 122 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 3 \tEpoch: 123 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 3 \tEpoch: 124 \tTraining Loss: 0.000 \tValidation Loss: 0.084\n",
      "Seed: 3 \tEpoch: 125 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 3 \tEpoch: 126 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 3 \tEpoch: 127 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 3 \tEpoch: 128 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 3 \tEpoch: 129 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 3 \tEpoch: 130 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 3 \tEpoch: 131 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 3 \tEpoch: 132 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 3 \tEpoch: 133 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 3 \tEpoch: 134 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 3 \tEpoch: 135 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 3 \tEpoch: 136 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 3 \tEpoch: 137 \tTraining Loss: 0.000 \tValidation Loss: 0.085\n",
      "Seed: 3 \tEpoch: 138 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 3 \tEpoch: 139 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 3 \tEpoch: 140 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 3 \tEpoch: 141 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 3 \tEpoch: 142 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 3 \tEpoch: 143 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 3 \tEpoch: 144 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 3 \tEpoch: 145 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 3 \tEpoch: 146 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 3 \tEpoch: 147 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 3 \tEpoch: 148 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Seed: 3 \tEpoch: 149 \tTraining Loss: 0.000 \tValidation Loss: 0.087\n",
      "Seed: 3 \tEpoch: 150 \tTraining Loss: 0.000 \tValidation Loss: 0.086\n",
      "Finished Training for seed 3 of model LeNet\n",
      "-------------------\n",
      "SEED: 1\n",
      "MODEL: ResNet\n",
      "-------------------\n",
      "Seed: 1 \tEpoch: 1 \tTraining Loss: 0.175 \tValidation Loss: 0.056\n",
      "Validation loss decreased (inf --> 0.056).  Saving model ...\n",
      "Seed: 1 \tEpoch: 2 \tTraining Loss: 0.055 \tValidation Loss: 0.049\n",
      "Validation loss decreased (0.056 --> 0.049).  Saving model ...\n",
      "Seed: 1 \tEpoch: 3 \tTraining Loss: 0.040 \tValidation Loss: 0.042\n",
      "Validation loss decreased (0.049 --> 0.042).  Saving model ...\n",
      "Seed: 1 \tEpoch: 4 \tTraining Loss: 0.030 \tValidation Loss: 0.041\n",
      "Validation loss decreased (0.042 --> 0.041).  Saving model ...\n",
      "Seed: 1 \tEpoch: 5 \tTraining Loss: 0.022 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.041 --> 0.031).  Saving model ...\n",
      "Seed: 1 \tEpoch: 6 \tTraining Loss: 0.019 \tValidation Loss: 0.046\n",
      "Seed: 1 \tEpoch: 7 \tTraining Loss: 0.014 \tValidation Loss: 0.038\n",
      "Seed: 1 \tEpoch: 8 \tTraining Loss: 0.014 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 9 \tTraining Loss: 0.009 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 10 \tTraining Loss: 0.010 \tValidation Loss: 0.039\n",
      "Seed: 1 \tEpoch: 11 \tTraining Loss: 0.007 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 12 \tTraining Loss: 0.006 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 13 \tTraining Loss: 0.008 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 14 \tTraining Loss: 0.007 \tValidation Loss: 0.036\n",
      "Seed: 1 \tEpoch: 15 \tTraining Loss: 0.004 \tValidation Loss: 0.028\n",
      "Validation loss decreased (0.031 --> 0.028).  Saving model ...\n",
      "Seed: 1 \tEpoch: 16 \tTraining Loss: 0.005 \tValidation Loss: 0.028\n",
      "Seed: 1 \tEpoch: 17 \tTraining Loss: 0.004 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 18 \tTraining Loss: 0.004 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 19 \tTraining Loss: 0.005 \tValidation Loss: 0.044\n",
      "Seed: 1 \tEpoch: 20 \tTraining Loss: 0.005 \tValidation Loss: 0.039\n",
      "Seed: 1 \tEpoch: 21 \tTraining Loss: 0.004 \tValidation Loss: 0.038\n",
      "Seed: 1 \tEpoch: 22 \tTraining Loss: 0.002 \tValidation Loss: 0.028\n",
      "Seed: 1 \tEpoch: 23 \tTraining Loss: 0.001 \tValidation Loss: 0.026\n",
      "Validation loss decreased (0.028 --> 0.026).  Saving model ...\n",
      "Seed: 1 \tEpoch: 24 \tTraining Loss: 0.000 \tValidation Loss: 0.027\n",
      "Seed: 1 \tEpoch: 25 \tTraining Loss: 0.000 \tValidation Loss: 0.027\n",
      "Seed: 1 \tEpoch: 26 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 27 \tTraining Loss: 0.003 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 28 \tTraining Loss: 0.002 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 29 \tTraining Loss: 0.005 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 30 \tTraining Loss: 0.003 \tValidation Loss: 0.038\n",
      "Seed: 1 \tEpoch: 31 \tTraining Loss: 0.007 \tValidation Loss: 0.039\n",
      "Seed: 1 \tEpoch: 32 \tTraining Loss: 0.004 \tValidation Loss: 0.037\n",
      "Seed: 1 \tEpoch: 33 \tTraining Loss: 0.006 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 34 \tTraining Loss: 0.003 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 35 \tTraining Loss: 0.004 \tValidation Loss: 0.048\n",
      "Seed: 1 \tEpoch: 36 \tTraining Loss: 0.005 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 37 \tTraining Loss: 0.001 \tValidation Loss: 0.027\n",
      "Seed: 1 \tEpoch: 38 \tTraining Loss: 0.004 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 39 \tTraining Loss: 0.003 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 40 \tTraining Loss: 0.006 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 41 \tTraining Loss: 0.005 \tValidation Loss: 0.038\n",
      "Seed: 1 \tEpoch: 42 \tTraining Loss: 0.005 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 43 \tTraining Loss: 0.003 \tValidation Loss: 0.036\n",
      "Seed: 1 \tEpoch: 44 \tTraining Loss: 0.003 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 45 \tTraining Loss: 0.005 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 46 \tTraining Loss: 0.002 \tValidation Loss: 0.027\n",
      "Seed: 1 \tEpoch: 47 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 48 \tTraining Loss: 0.002 \tValidation Loss: 0.028\n",
      "Seed: 1 \tEpoch: 49 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 50 \tTraining Loss: 0.005 \tValidation Loss: 0.038\n",
      "Seed: 1 \tEpoch: 51 \tTraining Loss: 0.005 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 52 \tTraining Loss: 0.006 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 53 \tTraining Loss: 0.004 \tValidation Loss: 0.038\n",
      "Seed: 1 \tEpoch: 54 \tTraining Loss: 0.003 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 55 \tTraining Loss: 0.002 \tValidation Loss: 0.038\n",
      "Seed: 1 \tEpoch: 56 \tTraining Loss: 0.004 \tValidation Loss: 0.027\n",
      "Seed: 1 \tEpoch: 57 \tTraining Loss: 0.001 \tValidation Loss: 0.029\n",
      "Seed: 1 \tEpoch: 58 \tTraining Loss: 0.001 \tValidation Loss: 0.029\n",
      "Seed: 1 \tEpoch: 59 \tTraining Loss: 0.005 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 60 \tTraining Loss: 0.007 \tValidation Loss: 0.037\n",
      "Seed: 1 \tEpoch: 61 \tTraining Loss: 0.003 \tValidation Loss: 0.042\n",
      "Seed: 1 \tEpoch: 62 \tTraining Loss: 0.005 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 63 \tTraining Loss: 0.003 \tValidation Loss: 0.029\n",
      "Seed: 1 \tEpoch: 64 \tTraining Loss: 0.002 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 65 \tTraining Loss: 0.002 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 66 \tTraining Loss: 0.006 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 67 \tTraining Loss: 0.003 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 68 \tTraining Loss: 0.004 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 69 \tTraining Loss: 0.002 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 70 \tTraining Loss: 0.004 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 71 \tTraining Loss: 0.004 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 72 \tTraining Loss: 0.003 \tValidation Loss: 0.041\n",
      "Seed: 1 \tEpoch: 73 \tTraining Loss: 0.002 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 74 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 1 \tEpoch: 75 \tTraining Loss: 0.002 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 76 \tTraining Loss: 0.004 \tValidation Loss: 0.037\n",
      "Seed: 1 \tEpoch: 77 \tTraining Loss: 0.004 \tValidation Loss: 0.036\n",
      "Seed: 1 \tEpoch: 78 \tTraining Loss: 0.004 \tValidation Loss: 0.027\n",
      "Seed: 1 \tEpoch: 79 \tTraining Loss: 0.003 \tValidation Loss: 0.028\n",
      "Seed: 1 \tEpoch: 80 \tTraining Loss: 0.005 \tValidation Loss: 0.042\n",
      "Seed: 1 \tEpoch: 81 \tTraining Loss: 0.006 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 82 \tTraining Loss: 0.002 \tValidation Loss: 0.039\n",
      "Seed: 1 \tEpoch: 83 \tTraining Loss: 0.003 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 84 \tTraining Loss: 0.002 \tValidation Loss: 0.029\n",
      "Seed: 1 \tEpoch: 85 \tTraining Loss: 0.000 \tValidation Loss: 0.029\n",
      "Seed: 1 \tEpoch: 86 \tTraining Loss: 0.002 \tValidation Loss: 0.036\n",
      "Seed: 1 \tEpoch: 87 \tTraining Loss: 0.005 \tValidation Loss: 0.036\n",
      "Seed: 1 \tEpoch: 88 \tTraining Loss: 0.005 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 89 \tTraining Loss: 0.004 \tValidation Loss: 0.040\n",
      "Seed: 1 \tEpoch: 90 \tTraining Loss: 0.004 \tValidation Loss: 0.038\n",
      "Seed: 1 \tEpoch: 91 \tTraining Loss: 0.004 \tValidation Loss: 0.042\n",
      "Seed: 1 \tEpoch: 92 \tTraining Loss: 0.003 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 93 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 94 \tTraining Loss: 0.004 \tValidation Loss: 0.037\n",
      "Seed: 1 \tEpoch: 95 \tTraining Loss: 0.006 \tValidation Loss: 0.026\n",
      "Validation loss decreased (0.026 --> 0.026).  Saving model ...\n",
      "Seed: 1 \tEpoch: 96 \tTraining Loss: 0.004 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 97 \tTraining Loss: 0.004 \tValidation Loss: 0.036\n",
      "Seed: 1 \tEpoch: 98 \tTraining Loss: 0.002 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 99 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 100 \tTraining Loss: 0.003 \tValidation Loss: 0.044\n",
      "Seed: 1 \tEpoch: 101 \tTraining Loss: 0.007 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 102 \tTraining Loss: 0.004 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 103 \tTraining Loss: 0.004 \tValidation Loss: 0.041\n",
      "Seed: 1 \tEpoch: 104 \tTraining Loss: 0.003 \tValidation Loss: 0.028\n",
      "Seed: 1 \tEpoch: 105 \tTraining Loss: 0.002 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 106 \tTraining Loss: 0.002 \tValidation Loss: 0.026\n",
      "Seed: 1 \tEpoch: 107 \tTraining Loss: 0.000 \tValidation Loss: 0.026\n",
      "Seed: 1 \tEpoch: 108 \tTraining Loss: 0.000 \tValidation Loss: 0.028\n",
      "Seed: 1 \tEpoch: 109 \tTraining Loss: 0.000 \tValidation Loss: 0.027\n",
      "Seed: 1 \tEpoch: 110 \tTraining Loss: 0.003 \tValidation Loss: 0.063\n",
      "Seed: 1 \tEpoch: 111 \tTraining Loss: 0.009 \tValidation Loss: 0.037\n",
      "Seed: 1 \tEpoch: 112 \tTraining Loss: 0.007 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 113 \tTraining Loss: 0.003 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 114 \tTraining Loss: 0.003 \tValidation Loss: 0.053\n",
      "Seed: 1 \tEpoch: 115 \tTraining Loss: 0.007 \tValidation Loss: 0.039\n",
      "Seed: 1 \tEpoch: 116 \tTraining Loss: 0.005 \tValidation Loss: 0.029\n",
      "Seed: 1 \tEpoch: 117 \tTraining Loss: 0.004 \tValidation Loss: 0.039\n",
      "Seed: 1 \tEpoch: 118 \tTraining Loss: 0.002 \tValidation Loss: 0.025\n",
      "Validation loss decreased (0.026 --> 0.025).  Saving model ...\n",
      "Seed: 1 \tEpoch: 119 \tTraining Loss: 0.002 \tValidation Loss: 0.041\n",
      "Seed: 1 \tEpoch: 120 \tTraining Loss: 0.004 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 121 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 122 \tTraining Loss: 0.003 \tValidation Loss: 0.029\n",
      "Seed: 1 \tEpoch: 123 \tTraining Loss: 0.003 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 124 \tTraining Loss: 0.002 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 125 \tTraining Loss: 0.005 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 126 \tTraining Loss: 0.005 \tValidation Loss: 0.028\n",
      "Seed: 1 \tEpoch: 127 \tTraining Loss: 0.003 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 128 \tTraining Loss: 0.004 \tValidation Loss: 0.046\n",
      "Seed: 1 \tEpoch: 129 \tTraining Loss: 0.006 \tValidation Loss: 0.044\n",
      "Seed: 1 \tEpoch: 130 \tTraining Loss: 0.005 \tValidation Loss: 0.028\n",
      "Seed: 1 \tEpoch: 131 \tTraining Loss: 0.003 \tValidation Loss: 0.040\n",
      "Seed: 1 \tEpoch: 132 \tTraining Loss: 0.004 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 133 \tTraining Loss: 0.002 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 134 \tTraining Loss: 0.002 \tValidation Loss: 0.044\n",
      "Seed: 1 \tEpoch: 135 \tTraining Loss: 0.003 \tValidation Loss: 0.049\n",
      "Seed: 1 \tEpoch: 136 \tTraining Loss: 0.005 \tValidation Loss: 0.029\n",
      "Seed: 1 \tEpoch: 137 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 138 \tTraining Loss: 0.000 \tValidation Loss: 0.028\n",
      "Seed: 1 \tEpoch: 139 \tTraining Loss: 0.003 \tValidation Loss: 0.055\n",
      "Seed: 1 \tEpoch: 140 \tTraining Loss: 0.005 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 141 \tTraining Loss: 0.002 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 142 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 143 \tTraining Loss: 0.001 \tValidation Loss: 0.037\n",
      "Seed: 1 \tEpoch: 144 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 145 \tTraining Loss: 0.003 \tValidation Loss: 0.045\n",
      "Seed: 1 \tEpoch: 146 \tTraining Loss: 0.008 \tValidation Loss: 0.041\n",
      "Seed: 1 \tEpoch: 147 \tTraining Loss: 0.004 \tValidation Loss: 0.030\n",
      "Seed: 1 \tEpoch: 148 \tTraining Loss: 0.006 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 149 \tTraining Loss: 0.006 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 150 \tTraining Loss: 0.003 \tValidation Loss: 0.039\n",
      "Finished Training for seed 1 of model ResNet\n",
      "-------------------\n",
      "SEED: 2\n",
      "MODEL: ResNet\n",
      "-------------------\n",
      "Seed: 2 \tEpoch: 1 \tTraining Loss: 0.178 \tValidation Loss: 0.055\n",
      "Validation loss decreased (inf --> 0.055).  Saving model ...\n",
      "Seed: 2 \tEpoch: 2 \tTraining Loss: 0.057 \tValidation Loss: 0.049\n",
      "Validation loss decreased (0.055 --> 0.049).  Saving model ...\n",
      "Seed: 2 \tEpoch: 3 \tTraining Loss: 0.041 \tValidation Loss: 0.034\n",
      "Validation loss decreased (0.049 --> 0.034).  Saving model ...\n",
      "Seed: 2 \tEpoch: 4 \tTraining Loss: 0.029 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 5 \tTraining Loss: 0.022 \tValidation Loss: 0.034\n",
      "Validation loss decreased (0.034 --> 0.034).  Saving model ...\n",
      "Seed: 2 \tEpoch: 6 \tTraining Loss: 0.016 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.034 --> 0.031).  Saving model ...\n",
      "Seed: 2 \tEpoch: 7 \tTraining Loss: 0.016 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 8 \tTraining Loss: 0.011 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 9 \tTraining Loss: 0.009 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 10 \tTraining Loss: 0.009 \tValidation Loss: 0.042\n",
      "Seed: 2 \tEpoch: 11 \tTraining Loss: 0.012 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.031 --> 0.031).  Saving model ...\n",
      "Seed: 2 \tEpoch: 12 \tTraining Loss: 0.008 \tValidation Loss: 0.029\n",
      "Validation loss decreased (0.031 --> 0.029).  Saving model ...\n",
      "Seed: 2 \tEpoch: 13 \tTraining Loss: 0.008 \tValidation Loss: 0.030\n",
      "Seed: 2 \tEpoch: 14 \tTraining Loss: 0.005 \tValidation Loss: 0.026\n",
      "Validation loss decreased (0.029 --> 0.026).  Saving model ...\n",
      "Seed: 2 \tEpoch: 15 \tTraining Loss: 0.005 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 16 \tTraining Loss: 0.002 \tValidation Loss: 0.026\n",
      "Validation loss decreased (0.026 --> 0.026).  Saving model ...\n",
      "Seed: 2 \tEpoch: 17 \tTraining Loss: 0.006 \tValidation Loss: 0.051\n",
      "Seed: 2 \tEpoch: 18 \tTraining Loss: 0.008 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 19 \tTraining Loss: 0.006 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 20 \tTraining Loss: 0.003 \tValidation Loss: 0.028\n",
      "Seed: 2 \tEpoch: 21 \tTraining Loss: 0.001 \tValidation Loss: 0.028\n",
      "Seed: 2 \tEpoch: 22 \tTraining Loss: 0.001 \tValidation Loss: 0.028\n",
      "Seed: 2 \tEpoch: 23 \tTraining Loss: 0.000 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 24 \tTraining Loss: 0.001 \tValidation Loss: 0.027\n",
      "Seed: 2 \tEpoch: 25 \tTraining Loss: 0.004 \tValidation Loss: 0.030\n",
      "Seed: 2 \tEpoch: 26 \tTraining Loss: 0.003 \tValidation Loss: 0.025\n",
      "Validation loss decreased (0.026 --> 0.025).  Saving model ...\n",
      "Seed: 2 \tEpoch: 27 \tTraining Loss: 0.004 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 28 \tTraining Loss: 0.002 \tValidation Loss: 0.031\n",
      "Seed: 2 \tEpoch: 29 \tTraining Loss: 0.006 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 30 \tTraining Loss: 0.008 \tValidation Loss: 0.041\n",
      "Seed: 2 \tEpoch: 31 \tTraining Loss: 0.005 \tValidation Loss: 0.031\n",
      "Seed: 2 \tEpoch: 32 \tTraining Loss: 0.004 \tValidation Loss: 0.030\n",
      "Seed: 2 \tEpoch: 33 \tTraining Loss: 0.001 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 34 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 35 \tTraining Loss: 0.001 \tValidation Loss: 0.027\n",
      "Seed: 2 \tEpoch: 36 \tTraining Loss: 0.002 \tValidation Loss: 0.031\n",
      "Seed: 2 \tEpoch: 37 \tTraining Loss: 0.003 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 38 \tTraining Loss: 0.002 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 39 \tTraining Loss: 0.001 \tValidation Loss: 0.027\n",
      "Seed: 2 \tEpoch: 40 \tTraining Loss: 0.001 \tValidation Loss: 0.028\n",
      "Seed: 2 \tEpoch: 41 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Seed: 2 \tEpoch: 42 \tTraining Loss: 0.004 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 43 \tTraining Loss: 0.005 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 44 \tTraining Loss: 0.004 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 45 \tTraining Loss: 0.008 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 46 \tTraining Loss: 0.006 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 47 \tTraining Loss: 0.002 \tValidation Loss: 0.027\n",
      "Seed: 2 \tEpoch: 48 \tTraining Loss: 0.003 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 49 \tTraining Loss: 0.005 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 50 \tTraining Loss: 0.004 \tValidation Loss: 0.038\n",
      "Seed: 2 \tEpoch: 51 \tTraining Loss: 0.004 \tValidation Loss: 0.028\n",
      "Seed: 2 \tEpoch: 52 \tTraining Loss: 0.002 \tValidation Loss: 0.023\n",
      "Validation loss decreased (0.025 --> 0.023).  Saving model ...\n",
      "Seed: 2 \tEpoch: 53 \tTraining Loss: 0.003 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 54 \tTraining Loss: 0.003 \tValidation Loss: 0.027\n",
      "Seed: 2 \tEpoch: 55 \tTraining Loss: 0.004 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 56 \tTraining Loss: 0.006 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 57 \tTraining Loss: 0.004 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 58 \tTraining Loss: 0.002 \tValidation Loss: 0.027\n",
      "Seed: 2 \tEpoch: 59 \tTraining Loss: 0.004 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 60 \tTraining Loss: 0.005 \tValidation Loss: 0.027\n",
      "Seed: 2 \tEpoch: 61 \tTraining Loss: 0.003 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 62 \tTraining Loss: 0.004 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 63 \tTraining Loss: 0.005 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 64 \tTraining Loss: 0.002 \tValidation Loss: 0.042\n",
      "Seed: 2 \tEpoch: 65 \tTraining Loss: 0.007 \tValidation Loss: 0.030\n",
      "Seed: 2 \tEpoch: 66 \tTraining Loss: 0.003 \tValidation Loss: 0.030\n",
      "Seed: 2 \tEpoch: 67 \tTraining Loss: 0.003 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 68 \tTraining Loss: 0.003 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 69 \tTraining Loss: 0.004 \tValidation Loss: 0.028\n",
      "Seed: 2 \tEpoch: 70 \tTraining Loss: 0.003 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 71 \tTraining Loss: 0.003 \tValidation Loss: 0.061\n",
      "Seed: 2 \tEpoch: 72 \tTraining Loss: 0.006 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 73 \tTraining Loss: 0.004 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 74 \tTraining Loss: 0.004 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 75 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 76 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 2 \tEpoch: 77 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 2 \tEpoch: 78 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 2 \tEpoch: 79 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 2 \tEpoch: 80 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 2 \tEpoch: 81 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 2 \tEpoch: 82 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 2 \tEpoch: 83 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 84 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 85 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 2 \tEpoch: 86 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 2 \tEpoch: 87 \tTraining Loss: 0.000 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 88 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 89 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 90 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 91 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 92 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 93 \tTraining Loss: 0.000 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 94 \tTraining Loss: 0.000 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 95 \tTraining Loss: 0.000 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 96 \tTraining Loss: 0.000 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 97 \tTraining Loss: 0.000 \tValidation Loss: 0.030\n",
      "Seed: 2 \tEpoch: 98 \tTraining Loss: 0.031 \tValidation Loss: 0.038\n",
      "Seed: 2 \tEpoch: 99 \tTraining Loss: 0.017 \tValidation Loss: 0.030\n",
      "Seed: 2 \tEpoch: 100 \tTraining Loss: 0.014 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 101 \tTraining Loss: 0.009 \tValidation Loss: 0.030\n",
      "Seed: 2 \tEpoch: 102 \tTraining Loss: 0.008 \tValidation Loss: 0.030\n",
      "Seed: 2 \tEpoch: 103 \tTraining Loss: 0.008 \tValidation Loss: 0.031\n",
      "Seed: 2 \tEpoch: 104 \tTraining Loss: 0.005 \tValidation Loss: 0.061\n",
      "Seed: 2 \tEpoch: 105 \tTraining Loss: 0.005 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 106 \tTraining Loss: 0.005 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 107 \tTraining Loss: 0.006 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 108 \tTraining Loss: 0.004 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 109 \tTraining Loss: 0.002 \tValidation Loss: 0.030\n",
      "Seed: 2 \tEpoch: 110 \tTraining Loss: 0.004 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 111 \tTraining Loss: 0.003 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 112 \tTraining Loss: 0.002 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 113 \tTraining Loss: 0.004 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 114 \tTraining Loss: 0.004 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 115 \tTraining Loss: 0.004 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 116 \tTraining Loss: 0.002 \tValidation Loss: 0.030\n",
      "Seed: 2 \tEpoch: 117 \tTraining Loss: 0.002 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 118 \tTraining Loss: 0.005 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 119 \tTraining Loss: 0.007 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 120 \tTraining Loss: 0.004 \tValidation Loss: 0.031\n",
      "Seed: 2 \tEpoch: 121 \tTraining Loss: 0.006 \tValidation Loss: 0.028\n",
      "Seed: 2 \tEpoch: 122 \tTraining Loss: 0.003 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 123 \tTraining Loss: 0.001 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 124 \tTraining Loss: 0.002 \tValidation Loss: 0.023\n",
      "Seed: 2 \tEpoch: 125 \tTraining Loss: 0.003 \tValidation Loss: 0.031\n",
      "Seed: 2 \tEpoch: 126 \tTraining Loss: 0.006 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 127 \tTraining Loss: 0.005 \tValidation Loss: 0.028\n",
      "Seed: 2 \tEpoch: 128 \tTraining Loss: 0.005 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 129 \tTraining Loss: 0.002 \tValidation Loss: 0.024\n",
      "Seed: 2 \tEpoch: 130 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 131 \tTraining Loss: 0.000 \tValidation Loss: 0.026\n",
      "Seed: 2 \tEpoch: 132 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 133 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 134 \tTraining Loss: 0.000 \tValidation Loss: 0.027\n",
      "Seed: 2 \tEpoch: 135 \tTraining Loss: 0.000 \tValidation Loss: 0.028\n",
      "Seed: 2 \tEpoch: 136 \tTraining Loss: 0.004 \tValidation Loss: 0.027\n",
      "Seed: 2 \tEpoch: 137 \tTraining Loss: 0.012 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 138 \tTraining Loss: 0.007 \tValidation Loss: 0.025\n",
      "Seed: 2 \tEpoch: 139 \tTraining Loss: 0.004 \tValidation Loss: 0.031\n",
      "Seed: 2 \tEpoch: 140 \tTraining Loss: 0.003 \tValidation Loss: 0.041\n",
      "Seed: 2 \tEpoch: 141 \tTraining Loss: 0.006 \tValidation Loss: 0.040\n",
      "Seed: 2 \tEpoch: 142 \tTraining Loss: 0.004 \tValidation Loss: 0.028\n",
      "Seed: 2 \tEpoch: 143 \tTraining Loss: 0.006 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 144 \tTraining Loss: 0.003 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 145 \tTraining Loss: 0.004 \tValidation Loss: 0.029\n",
      "Seed: 2 \tEpoch: 146 \tTraining Loss: 0.002 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 147 \tTraining Loss: 0.002 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 148 \tTraining Loss: 0.006 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 149 \tTraining Loss: 0.006 \tValidation Loss: 0.031\n",
      "Seed: 2 \tEpoch: 150 \tTraining Loss: 0.004 \tValidation Loss: 0.037\n",
      "Finished Training for seed 2 of model ResNet\n",
      "-------------------\n",
      "SEED: 3\n",
      "MODEL: ResNet\n",
      "-------------------\n",
      "Seed: 3 \tEpoch: 1 \tTraining Loss: 0.184 \tValidation Loss: 0.050\n",
      "Validation loss decreased (inf --> 0.050).  Saving model ...\n",
      "Seed: 3 \tEpoch: 2 \tTraining Loss: 0.061 \tValidation Loss: 0.049\n",
      "Validation loss decreased (0.050 --> 0.049).  Saving model ...\n",
      "Seed: 3 \tEpoch: 3 \tTraining Loss: 0.037 \tValidation Loss: 0.048\n",
      "Validation loss decreased (0.049 --> 0.048).  Saving model ...\n",
      "Seed: 3 \tEpoch: 4 \tTraining Loss: 0.028 \tValidation Loss: 0.036\n",
      "Validation loss decreased (0.048 --> 0.036).  Saving model ...\n",
      "Seed: 3 \tEpoch: 5 \tTraining Loss: 0.022 \tValidation Loss: 0.040\n",
      "Seed: 3 \tEpoch: 6 \tTraining Loss: 0.021 \tValidation Loss: 0.040\n",
      "Seed: 3 \tEpoch: 7 \tTraining Loss: 0.016 \tValidation Loss: 0.034\n",
      "Validation loss decreased (0.036 --> 0.034).  Saving model ...\n",
      "Seed: 3 \tEpoch: 8 \tTraining Loss: 0.011 \tValidation Loss: 0.039\n",
      "Seed: 3 \tEpoch: 9 \tTraining Loss: 0.010 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.034 --> 0.031).  Saving model ...\n",
      "Seed: 3 \tEpoch: 10 \tTraining Loss: 0.011 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 11 \tTraining Loss: 0.010 \tValidation Loss: 0.036\n",
      "Seed: 3 \tEpoch: 12 \tTraining Loss: 0.008 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 13 \tTraining Loss: 0.008 \tValidation Loss: 0.038\n",
      "Seed: 3 \tEpoch: 14 \tTraining Loss: 0.005 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 15 \tTraining Loss: 0.006 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.031 --> 0.031).  Saving model ...\n",
      "Seed: 3 \tEpoch: 16 \tTraining Loss: 0.004 \tValidation Loss: 0.035\n",
      "Seed: 3 \tEpoch: 17 \tTraining Loss: 0.003 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 18 \tTraining Loss: 0.005 \tValidation Loss: 0.045\n",
      "Seed: 3 \tEpoch: 19 \tTraining Loss: 0.005 \tValidation Loss: 0.041\n",
      "Seed: 3 \tEpoch: 20 \tTraining Loss: 0.006 \tValidation Loss: 0.028\n",
      "Validation loss decreased (0.031 --> 0.028).  Saving model ...\n",
      "Seed: 3 \tEpoch: 21 \tTraining Loss: 0.004 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 22 \tTraining Loss: 0.005 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 23 \tTraining Loss: 0.003 \tValidation Loss: 0.035\n",
      "Seed: 3 \tEpoch: 24 \tTraining Loss: 0.003 \tValidation Loss: 0.029\n",
      "Seed: 3 \tEpoch: 25 \tTraining Loss: 0.002 \tValidation Loss: 0.029\n",
      "Seed: 3 \tEpoch: 26 \tTraining Loss: 0.004 \tValidation Loss: 0.043\n",
      "Seed: 3 \tEpoch: 27 \tTraining Loss: 0.008 \tValidation Loss: 0.049\n",
      "Seed: 3 \tEpoch: 28 \tTraining Loss: 0.003 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 29 \tTraining Loss: 0.003 \tValidation Loss: 0.037\n",
      "Seed: 3 \tEpoch: 30 \tTraining Loss: 0.002 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 31 \tTraining Loss: 0.002 \tValidation Loss: 0.028\n",
      "Validation loss decreased (0.028 --> 0.028).  Saving model ...\n",
      "Seed: 3 \tEpoch: 32 \tTraining Loss: 0.001 \tValidation Loss: 0.025\n",
      "Validation loss decreased (0.028 --> 0.025).  Saving model ...\n",
      "Seed: 3 \tEpoch: 33 \tTraining Loss: 0.001 \tValidation Loss: 0.029\n",
      "Seed: 3 \tEpoch: 34 \tTraining Loss: 0.003 \tValidation Loss: 0.030\n",
      "Seed: 3 \tEpoch: 35 \tTraining Loss: 0.004 \tValidation Loss: 0.026\n",
      "Seed: 3 \tEpoch: 36 \tTraining Loss: 0.003 \tValidation Loss: 0.027\n",
      "Seed: 3 \tEpoch: 37 \tTraining Loss: 0.004 \tValidation Loss: 0.028\n",
      "Seed: 3 \tEpoch: 38 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Seed: 3 \tEpoch: 39 \tTraining Loss: 0.002 \tValidation Loss: 0.028\n",
      "Seed: 3 \tEpoch: 40 \tTraining Loss: 0.001 \tValidation Loss: 0.026\n",
      "Seed: 3 \tEpoch: 41 \tTraining Loss: 0.003 \tValidation Loss: 0.029\n",
      "Seed: 3 \tEpoch: 42 \tTraining Loss: 0.005 \tValidation Loss: 0.051\n",
      "Seed: 3 \tEpoch: 43 \tTraining Loss: 0.005 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 44 \tTraining Loss: 0.007 \tValidation Loss: 0.030\n",
      "Seed: 3 \tEpoch: 45 \tTraining Loss: 0.008 \tValidation Loss: 0.060\n",
      "Seed: 3 \tEpoch: 46 \tTraining Loss: 0.006 \tValidation Loss: 0.026\n",
      "Seed: 3 \tEpoch: 47 \tTraining Loss: 0.003 \tValidation Loss: 0.029\n",
      "Seed: 3 \tEpoch: 48 \tTraining Loss: 0.002 \tValidation Loss: 0.030\n",
      "Seed: 3 \tEpoch: 49 \tTraining Loss: 0.003 \tValidation Loss: 0.030\n",
      "Seed: 3 \tEpoch: 50 \tTraining Loss: 0.003 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 51 \tTraining Loss: 0.005 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 52 \tTraining Loss: 0.006 \tValidation Loss: 0.027\n",
      "Seed: 3 \tEpoch: 53 \tTraining Loss: 0.005 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 54 \tTraining Loss: 0.003 \tValidation Loss: 0.037\n",
      "Seed: 3 \tEpoch: 55 \tTraining Loss: 0.002 \tValidation Loss: 0.029\n",
      "Seed: 3 \tEpoch: 56 \tTraining Loss: 0.001 \tValidation Loss: 0.027\n",
      "Seed: 3 \tEpoch: 57 \tTraining Loss: 0.001 \tValidation Loss: 0.026\n",
      "Seed: 3 \tEpoch: 58 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Validation loss decreased (0.025 --> 0.024).  Saving model ...\n",
      "Seed: 3 \tEpoch: 59 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Validation loss decreased (0.024 --> 0.023).  Saving model ...\n",
      "Seed: 3 \tEpoch: 60 \tTraining Loss: 0.000 \tValidation Loss: 0.022\n",
      "Validation loss decreased (0.023 --> 0.022).  Saving model ...\n",
      "Seed: 3 \tEpoch: 61 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 62 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 3 \tEpoch: 63 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 64 \tTraining Loss: 0.000 \tValidation Loss: 0.022\n",
      "Seed: 3 \tEpoch: 65 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 66 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 67 \tTraining Loss: 0.000 \tValidation Loss: 0.022\n",
      "Validation loss decreased (0.022 --> 0.022).  Saving model ...\n",
      "Seed: 3 \tEpoch: 68 \tTraining Loss: 0.000 \tValidation Loss: 0.022\n",
      "Validation loss decreased (0.022 --> 0.022).  Saving model ...\n",
      "Seed: 3 \tEpoch: 69 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 70 \tTraining Loss: 0.000 \tValidation Loss: 0.022\n",
      "Seed: 3 \tEpoch: 71 \tTraining Loss: 0.000 \tValidation Loss: 0.022\n",
      "Seed: 3 \tEpoch: 72 \tTraining Loss: 0.000 \tValidation Loss: 0.022\n",
      "Validation loss decreased (0.022 --> 0.022).  Saving model ...\n",
      "Seed: 3 \tEpoch: 73 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 74 \tTraining Loss: 0.000 \tValidation Loss: 0.022\n",
      "Seed: 3 \tEpoch: 75 \tTraining Loss: 0.000 \tValidation Loss: 0.022\n",
      "Seed: 3 \tEpoch: 76 \tTraining Loss: 0.023 \tValidation Loss: 0.050\n",
      "Seed: 3 \tEpoch: 77 \tTraining Loss: 0.015 \tValidation Loss: 0.037\n",
      "Seed: 3 \tEpoch: 78 \tTraining Loss: 0.009 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 79 \tTraining Loss: 0.010 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 80 \tTraining Loss: 0.005 \tValidation Loss: 0.030\n",
      "Seed: 3 \tEpoch: 81 \tTraining Loss: 0.007 \tValidation Loss: 0.040\n",
      "Seed: 3 \tEpoch: 82 \tTraining Loss: 0.005 \tValidation Loss: 0.028\n",
      "Seed: 3 \tEpoch: 83 \tTraining Loss: 0.003 \tValidation Loss: 0.045\n",
      "Seed: 3 \tEpoch: 84 \tTraining Loss: 0.003 \tValidation Loss: 0.028\n",
      "Seed: 3 \tEpoch: 85 \tTraining Loss: 0.004 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 86 \tTraining Loss: 0.002 \tValidation Loss: 0.027\n",
      "Seed: 3 \tEpoch: 87 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 3 \tEpoch: 88 \tTraining Loss: 0.005 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 89 \tTraining Loss: 0.006 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 90 \tTraining Loss: 0.006 \tValidation Loss: 0.044\n",
      "Seed: 3 \tEpoch: 91 \tTraining Loss: 0.004 \tValidation Loss: 0.028\n",
      "Seed: 3 \tEpoch: 92 \tTraining Loss: 0.005 \tValidation Loss: 0.029\n",
      "Seed: 3 \tEpoch: 93 \tTraining Loss: 0.004 \tValidation Loss: 0.036\n",
      "Seed: 3 \tEpoch: 94 \tTraining Loss: 0.006 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 95 \tTraining Loss: 0.008 \tValidation Loss: 0.026\n",
      "Seed: 3 \tEpoch: 96 \tTraining Loss: 0.002 \tValidation Loss: 0.028\n",
      "Seed: 3 \tEpoch: 97 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 98 \tTraining Loss: 0.001 \tValidation Loss: 0.029\n",
      "Seed: 3 \tEpoch: 99 \tTraining Loss: 0.001 \tValidation Loss: 0.026\n",
      "Seed: 3 \tEpoch: 100 \tTraining Loss: 0.000 \tValidation Loss: 0.027\n",
      "Seed: 3 \tEpoch: 101 \tTraining Loss: 0.000 \tValidation Loss: 0.026\n",
      "Seed: 3 \tEpoch: 102 \tTraining Loss: 0.000 \tValidation Loss: 0.026\n",
      "Seed: 3 \tEpoch: 103 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 3 \tEpoch: 104 \tTraining Loss: 0.001 \tValidation Loss: 0.027\n",
      "Seed: 3 \tEpoch: 105 \tTraining Loss: 0.002 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 106 \tTraining Loss: 0.011 \tValidation Loss: 0.040\n",
      "Seed: 3 \tEpoch: 107 \tTraining Loss: 0.011 \tValidation Loss: 0.036\n",
      "Seed: 3 \tEpoch: 108 \tTraining Loss: 0.006 \tValidation Loss: 0.029\n",
      "Seed: 3 \tEpoch: 109 \tTraining Loss: 0.005 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 110 \tTraining Loss: 0.005 \tValidation Loss: 0.030\n",
      "Seed: 3 \tEpoch: 111 \tTraining Loss: 0.005 \tValidation Loss: 0.049\n",
      "Seed: 3 \tEpoch: 112 \tTraining Loss: 0.007 \tValidation Loss: 0.040\n",
      "Seed: 3 \tEpoch: 113 \tTraining Loss: 0.005 \tValidation Loss: 0.029\n",
      "Seed: 3 \tEpoch: 114 \tTraining Loss: 0.003 \tValidation Loss: 0.026\n",
      "Seed: 3 \tEpoch: 115 \tTraining Loss: 0.004 \tValidation Loss: 0.036\n",
      "Seed: 3 \tEpoch: 116 \tTraining Loss: 0.002 \tValidation Loss: 0.025\n",
      "Seed: 3 \tEpoch: 117 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 3 \tEpoch: 118 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 119 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 120 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 3 \tEpoch: 121 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 122 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 123 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 124 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 125 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 3 \tEpoch: 126 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 127 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 128 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 129 \tTraining Loss: 0.000 \tValidation Loss: 0.022\n",
      "Seed: 3 \tEpoch: 130 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 131 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 132 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 133 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 134 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 135 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 136 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 137 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 138 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 139 \tTraining Loss: 0.000 \tValidation Loss: 0.023\n",
      "Seed: 3 \tEpoch: 140 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 3 \tEpoch: 141 \tTraining Loss: 0.000 \tValidation Loss: 0.024\n",
      "Seed: 3 \tEpoch: 142 \tTraining Loss: 0.000 \tValidation Loss: 0.025\n",
      "Seed: 3 \tEpoch: 143 \tTraining Loss: 0.030 \tValidation Loss: 0.041\n",
      "Seed: 3 \tEpoch: 144 \tTraining Loss: 0.021 \tValidation Loss: 0.062\n",
      "Seed: 3 \tEpoch: 145 \tTraining Loss: 0.012 \tValidation Loss: 0.030\n",
      "Seed: 3 \tEpoch: 146 \tTraining Loss: 0.011 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 147 \tTraining Loss: 0.006 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 148 \tTraining Loss: 0.007 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 149 \tTraining Loss: 0.006 \tValidation Loss: 0.029\n",
      "Seed: 3 \tEpoch: 150 \tTraining Loss: 0.006 \tValidation Loss: 0.038\n",
      "Finished Training for seed 3 of model ResNet\n",
      "-------------------\n",
      "SEED: 1\n",
      "MODEL: ConvNet\n",
      "-------------------\n",
      "Seed: 1 \tEpoch: 1 \tTraining Loss: 0.134 \tValidation Loss: 0.056\n",
      "Validation loss decreased (inf --> 0.056).  Saving model ...\n",
      "Seed: 1 \tEpoch: 2 \tTraining Loss: 0.046 \tValidation Loss: 0.043\n",
      "Validation loss decreased (0.056 --> 0.043).  Saving model ...\n",
      "Seed: 1 \tEpoch: 3 \tTraining Loss: 0.032 \tValidation Loss: 0.039\n",
      "Validation loss decreased (0.043 --> 0.039).  Saving model ...\n",
      "Seed: 1 \tEpoch: 4 \tTraining Loss: 0.026 \tValidation Loss: 0.044\n",
      "Seed: 1 \tEpoch: 5 \tTraining Loss: 0.020 \tValidation Loss: 0.039\n",
      "Seed: 1 \tEpoch: 6 \tTraining Loss: 0.018 \tValidation Loss: 0.034\n",
      "Validation loss decreased (0.039 --> 0.034).  Saving model ...\n",
      "Seed: 1 \tEpoch: 7 \tTraining Loss: 0.014 \tValidation Loss: 0.039\n",
      "Seed: 1 \tEpoch: 8 \tTraining Loss: 0.011 \tValidation Loss: 0.036\n",
      "Seed: 1 \tEpoch: 9 \tTraining Loss: 0.009 \tValidation Loss: 0.044\n",
      "Seed: 1 \tEpoch: 10 \tTraining Loss: 0.007 \tValidation Loss: 0.048\n",
      "Seed: 1 \tEpoch: 11 \tTraining Loss: 0.007 \tValidation Loss: 0.038\n",
      "Seed: 1 \tEpoch: 12 \tTraining Loss: 0.004 \tValidation Loss: 0.041\n",
      "Seed: 1 \tEpoch: 13 \tTraining Loss: 0.004 \tValidation Loss: 0.041\n",
      "Seed: 1 \tEpoch: 14 \tTraining Loss: 0.004 \tValidation Loss: 0.037\n",
      "Seed: 1 \tEpoch: 15 \tTraining Loss: 0.002 \tValidation Loss: 0.036\n",
      "Seed: 1 \tEpoch: 16 \tTraining Loss: 0.002 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 17 \tTraining Loss: 0.002 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 18 \tTraining Loss: 0.001 \tValidation Loss: 0.039\n",
      "Seed: 1 \tEpoch: 19 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 20 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 1 \tEpoch: 21 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 22 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 23 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 24 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Validation loss decreased (0.034 --> 0.033).  Saving model ...\n",
      "Seed: 1 \tEpoch: 25 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 26 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 1 \tEpoch: 27 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 28 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 1 \tEpoch: 29 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 30 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 31 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 32 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 33 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 34 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 35 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 36 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 37 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 38 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 39 \tTraining Loss: 0.001 \tValidation Loss: 0.040\n",
      "Seed: 1 \tEpoch: 40 \tTraining Loss: 0.014 \tValidation Loss: 0.066\n",
      "Seed: 1 \tEpoch: 41 \tTraining Loss: 0.013 \tValidation Loss: 0.048\n",
      "Seed: 1 \tEpoch: 42 \tTraining Loss: 0.007 \tValidation Loss: 0.033\n",
      "Validation loss decreased (0.033 --> 0.033).  Saving model ...\n",
      "Seed: 1 \tEpoch: 43 \tTraining Loss: 0.003 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 44 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 45 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 46 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 47 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Validation loss decreased (0.033 --> 0.033).  Saving model ...\n",
      "Seed: 1 \tEpoch: 48 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 49 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 50 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 51 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Validation loss decreased (0.033 --> 0.033).  Saving model ...\n",
      "Seed: 1 \tEpoch: 52 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 53 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 54 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Validation loss decreased (0.033 --> 0.032).  Saving model ...\n",
      "Seed: 1 \tEpoch: 55 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 56 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Validation loss decreased (0.032 --> 0.032).  Saving model ...\n",
      "Seed: 1 \tEpoch: 57 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 58 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 59 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 60 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Validation loss decreased (0.032 --> 0.032).  Saving model ...\n",
      "Seed: 1 \tEpoch: 61 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.032 --> 0.031).  Saving model ...\n",
      "Seed: 1 \tEpoch: 62 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 63 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 64 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 65 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 66 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 67 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 68 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 69 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 70 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 71 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 72 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 73 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 74 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 75 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 76 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 77 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 78 \tTraining Loss: 0.026 \tValidation Loss: 0.044\n",
      "Seed: 1 \tEpoch: 79 \tTraining Loss: 0.012 \tValidation Loss: 0.057\n",
      "Seed: 1 \tEpoch: 80 \tTraining Loss: 0.007 \tValidation Loss: 0.041\n",
      "Seed: 1 \tEpoch: 81 \tTraining Loss: 0.004 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 82 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 1 \tEpoch: 83 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 84 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 85 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 86 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 87 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 88 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 89 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 90 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 91 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 92 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 93 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 94 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.031 --> 0.031).  Saving model ...\n",
      "Seed: 1 \tEpoch: 95 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 96 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.031 --> 0.031).  Saving model ...\n",
      "Seed: 1 \tEpoch: 97 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 98 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 99 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 100 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.031 --> 0.031).  Saving model ...\n",
      "Seed: 1 \tEpoch: 101 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Validation loss decreased (0.031 --> 0.030).  Saving model ...\n",
      "Seed: 1 \tEpoch: 102 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 103 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 104 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 105 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 106 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 107 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 108 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 109 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 110 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 111 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 112 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 113 \tTraining Loss: 0.016 \tValidation Loss: 0.052\n",
      "Seed: 1 \tEpoch: 114 \tTraining Loss: 0.019 \tValidation Loss: 0.041\n",
      "Seed: 1 \tEpoch: 115 \tTraining Loss: 0.008 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 116 \tTraining Loss: 0.005 \tValidation Loss: 0.035\n",
      "Seed: 1 \tEpoch: 117 \tTraining Loss: 0.002 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 118 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 1 \tEpoch: 119 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 1 \tEpoch: 120 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 121 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 122 \tTraining Loss: 0.000 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 123 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 124 \tTraining Loss: 0.000 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 125 \tTraining Loss: 0.000 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 126 \tTraining Loss: 0.000 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 127 \tTraining Loss: 0.000 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 128 \tTraining Loss: 0.000 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 129 \tTraining Loss: 0.000 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 130 \tTraining Loss: 0.000 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 131 \tTraining Loss: 0.000 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 132 \tTraining Loss: 0.000 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 133 \tTraining Loss: 0.000 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 134 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 135 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 136 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 137 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 138 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 139 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 140 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 141 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 142 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 143 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 144 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 145 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 1 \tEpoch: 146 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 1 \tEpoch: 147 \tTraining Loss: 0.018 \tValidation Loss: 0.063\n",
      "Seed: 1 \tEpoch: 148 \tTraining Loss: 0.014 \tValidation Loss: 0.047\n",
      "Seed: 1 \tEpoch: 149 \tTraining Loss: 0.008 \tValidation Loss: 0.045\n",
      "Seed: 1 \tEpoch: 150 \tTraining Loss: 0.003 \tValidation Loss: 0.033\n",
      "Finished Training for seed 1 of model ConvNet\n",
      "-------------------\n",
      "SEED: 2\n",
      "MODEL: ConvNet\n",
      "-------------------\n",
      "Seed: 2 \tEpoch: 1 \tTraining Loss: 0.129 \tValidation Loss: 0.066\n",
      "Validation loss decreased (inf --> 0.066).  Saving model ...\n",
      "Seed: 2 \tEpoch: 2 \tTraining Loss: 0.048 \tValidation Loss: 0.041\n",
      "Validation loss decreased (0.066 --> 0.041).  Saving model ...\n",
      "Seed: 2 \tEpoch: 3 \tTraining Loss: 0.033 \tValidation Loss: 0.042\n",
      "Seed: 2 \tEpoch: 4 \tTraining Loss: 0.028 \tValidation Loss: 0.038\n",
      "Validation loss decreased (0.041 --> 0.038).  Saving model ...\n",
      "Seed: 2 \tEpoch: 5 \tTraining Loss: 0.021 \tValidation Loss: 0.042\n",
      "Seed: 2 \tEpoch: 6 \tTraining Loss: 0.018 \tValidation Loss: 0.039\n",
      "Seed: 2 \tEpoch: 7 \tTraining Loss: 0.015 \tValidation Loss: 0.036\n",
      "Validation loss decreased (0.038 --> 0.036).  Saving model ...\n",
      "Seed: 2 \tEpoch: 8 \tTraining Loss: 0.012 \tValidation Loss: 0.040\n",
      "Seed: 2 \tEpoch: 9 \tTraining Loss: 0.010 \tValidation Loss: 0.046\n",
      "Seed: 2 \tEpoch: 10 \tTraining Loss: 0.009 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 11 \tTraining Loss: 0.007 \tValidation Loss: 0.039\n",
      "Seed: 2 \tEpoch: 12 \tTraining Loss: 0.005 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 13 \tTraining Loss: 0.005 \tValidation Loss: 0.040\n",
      "Seed: 2 \tEpoch: 14 \tTraining Loss: 0.004 \tValidation Loss: 0.044\n",
      "Seed: 2 \tEpoch: 15 \tTraining Loss: 0.003 \tValidation Loss: 0.035\n",
      "Validation loss decreased (0.036 --> 0.035).  Saving model ...\n",
      "Seed: 2 \tEpoch: 16 \tTraining Loss: 0.002 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 17 \tTraining Loss: 0.002 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 18 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 19 \tTraining Loss: 0.001 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 20 \tTraining Loss: 0.001 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 21 \tTraining Loss: 0.001 \tValidation Loss: 0.038\n",
      "Seed: 2 \tEpoch: 22 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 23 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 24 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 25 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 26 \tTraining Loss: 0.001 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 27 \tTraining Loss: 0.001 \tValidation Loss: 0.038\n",
      "Seed: 2 \tEpoch: 28 \tTraining Loss: 0.001 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 29 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 30 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 31 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 32 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 33 \tTraining Loss: 0.001 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 34 \tTraining Loss: 0.001 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 35 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 36 \tTraining Loss: 0.001 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 37 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 38 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 39 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 40 \tTraining Loss: 0.002 \tValidation Loss: 0.068\n",
      "Seed: 2 \tEpoch: 41 \tTraining Loss: 0.022 \tValidation Loss: 0.040\n",
      "Seed: 2 \tEpoch: 42 \tTraining Loss: 0.009 \tValidation Loss: 0.039\n",
      "Seed: 2 \tEpoch: 43 \tTraining Loss: 0.004 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 44 \tTraining Loss: 0.002 \tValidation Loss: 0.035\n",
      "Validation loss decreased (0.035 --> 0.035).  Saving model ...\n",
      "Seed: 2 \tEpoch: 45 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 46 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 47 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 48 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 49 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 50 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 51 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 52 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 53 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 54 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 55 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 56 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 57 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Validation loss decreased (0.035 --> 0.034).  Saving model ...\n",
      "Seed: 2 \tEpoch: 58 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 59 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 60 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 61 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 62 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 63 \tTraining Loss: 0.001 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 64 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 65 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 66 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 67 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 68 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 69 \tTraining Loss: 0.016 \tValidation Loss: 0.044\n",
      "Seed: 2 \tEpoch: 70 \tTraining Loss: 0.016 \tValidation Loss: 0.039\n",
      "Seed: 2 \tEpoch: 71 \tTraining Loss: 0.009 \tValidation Loss: 0.046\n",
      "Seed: 2 \tEpoch: 72 \tTraining Loss: 0.003 \tValidation Loss: 0.037\n",
      "Seed: 2 \tEpoch: 73 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 74 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 75 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Validation loss decreased (0.034 --> 0.034).  Saving model ...\n",
      "Seed: 2 \tEpoch: 76 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 77 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 78 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 79 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 80 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 81 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 82 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 83 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Validation loss decreased (0.034 --> 0.034).  Saving model ...\n",
      "Seed: 2 \tEpoch: 84 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 85 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 86 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 87 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 88 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 89 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 90 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 91 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 92 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 93 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 94 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 95 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 96 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 97 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 98 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 99 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 100 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Validation loss decreased (0.034 --> 0.034).  Saving model ...\n",
      "Seed: 2 \tEpoch: 101 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 102 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 103 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 104 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 105 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 106 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 107 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Validation loss decreased (0.034 --> 0.033).  Saving model ...\n",
      "Seed: 2 \tEpoch: 108 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 109 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 2 \tEpoch: 110 \tTraining Loss: 0.002 \tValidation Loss: 0.086\n",
      "Seed: 2 \tEpoch: 111 \tTraining Loss: 0.036 \tValidation Loss: 0.042\n",
      "Seed: 2 \tEpoch: 112 \tTraining Loss: 0.012 \tValidation Loss: 0.040\n",
      "Seed: 2 \tEpoch: 113 \tTraining Loss: 0.006 \tValidation Loss: 0.036\n",
      "Seed: 2 \tEpoch: 114 \tTraining Loss: 0.004 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 115 \tTraining Loss: 0.002 \tValidation Loss: 0.033\n",
      "Validation loss decreased (0.033 --> 0.033).  Saving model ...\n",
      "Seed: 2 \tEpoch: 116 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 117 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 118 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Validation loss decreased (0.033 --> 0.032).  Saving model ...\n",
      "Seed: 2 \tEpoch: 119 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Validation loss decreased (0.032 --> 0.032).  Saving model ...\n",
      "Seed: 2 \tEpoch: 120 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 121 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 122 \tTraining Loss: 0.000 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 123 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 124 \tTraining Loss: 0.000 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 125 \tTraining Loss: 0.000 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 126 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 127 \tTraining Loss: 0.000 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 128 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 129 \tTraining Loss: 0.000 \tValidation Loss: 0.032\n",
      "Validation loss decreased (0.032 --> 0.032).  Saving model ...\n",
      "Seed: 2 \tEpoch: 130 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 131 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 132 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 133 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Validation loss decreased (0.032 --> 0.032).  Saving model ...\n",
      "Seed: 2 \tEpoch: 134 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 135 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 136 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 137 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 138 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 2 \tEpoch: 139 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 140 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 141 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 142 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 143 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 144 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 145 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 2 \tEpoch: 146 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 147 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 148 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 149 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 2 \tEpoch: 150 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Finished Training for seed 2 of model ConvNet\n",
      "-------------------\n",
      "SEED: 3\n",
      "MODEL: ConvNet\n",
      "-------------------\n",
      "Seed: 3 \tEpoch: 1 \tTraining Loss: 0.138 \tValidation Loss: 0.068\n",
      "Validation loss decreased (inf --> 0.068).  Saving model ...\n",
      "Seed: 3 \tEpoch: 2 \tTraining Loss: 0.049 \tValidation Loss: 0.050\n",
      "Validation loss decreased (0.068 --> 0.050).  Saving model ...\n",
      "Seed: 3 \tEpoch: 3 \tTraining Loss: 0.035 \tValidation Loss: 0.040\n",
      "Validation loss decreased (0.050 --> 0.040).  Saving model ...\n",
      "Seed: 3 \tEpoch: 4 \tTraining Loss: 0.028 \tValidation Loss: 0.040\n",
      "Validation loss decreased (0.040 --> 0.040).  Saving model ...\n",
      "Seed: 3 \tEpoch: 5 \tTraining Loss: 0.021 \tValidation Loss: 0.042\n",
      "Seed: 3 \tEpoch: 6 \tTraining Loss: 0.018 \tValidation Loss: 0.043\n",
      "Seed: 3 \tEpoch: 7 \tTraining Loss: 0.015 \tValidation Loss: 0.035\n",
      "Validation loss decreased (0.040 --> 0.035).  Saving model ...\n",
      "Seed: 3 \tEpoch: 8 \tTraining Loss: 0.013 \tValidation Loss: 0.032\n",
      "Validation loss decreased (0.035 --> 0.032).  Saving model ...\n",
      "Seed: 3 \tEpoch: 9 \tTraining Loss: 0.011 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 10 \tTraining Loss: 0.008 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 11 \tTraining Loss: 0.006 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 12 \tTraining Loss: 0.005 \tValidation Loss: 0.038\n",
      "Seed: 3 \tEpoch: 13 \tTraining Loss: 0.005 \tValidation Loss: 0.045\n",
      "Seed: 3 \tEpoch: 14 \tTraining Loss: 0.004 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 15 \tTraining Loss: 0.003 \tValidation Loss: 0.037\n",
      "Seed: 3 \tEpoch: 16 \tTraining Loss: 0.003 \tValidation Loss: 0.037\n",
      "Seed: 3 \tEpoch: 17 \tTraining Loss: 0.002 \tValidation Loss: 0.040\n",
      "Seed: 3 \tEpoch: 18 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 19 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 20 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 3 \tEpoch: 21 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 22 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 23 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 3 \tEpoch: 24 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 3 \tEpoch: 25 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 3 \tEpoch: 26 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 3 \tEpoch: 27 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 28 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 3 \tEpoch: 29 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 3 \tEpoch: 30 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 31 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 3 \tEpoch: 32 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 33 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 34 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 3 \tEpoch: 35 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 36 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 3 \tEpoch: 37 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 3 \tEpoch: 38 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 3 \tEpoch: 39 \tTraining Loss: 0.010 \tValidation Loss: 0.052\n",
      "Seed: 3 \tEpoch: 40 \tTraining Loss: 0.014 \tValidation Loss: 0.047\n",
      "Seed: 3 \tEpoch: 41 \tTraining Loss: 0.008 \tValidation Loss: 0.036\n",
      "Seed: 3 \tEpoch: 42 \tTraining Loss: 0.004 \tValidation Loss: 0.039\n",
      "Seed: 3 \tEpoch: 43 \tTraining Loss: 0.002 \tValidation Loss: 0.035\n",
      "Seed: 3 \tEpoch: 44 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 45 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 46 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 47 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 48 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 49 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 50 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 51 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 52 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 53 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 54 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 55 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 56 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 57 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 58 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 59 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 60 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 61 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 62 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Validation loss decreased (0.032 --> 0.032).  Saving model ...\n",
      "Seed: 3 \tEpoch: 63 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 64 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 65 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 66 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Validation loss decreased (0.032 --> 0.032).  Saving model ...\n",
      "Seed: 3 \tEpoch: 67 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 68 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 69 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 70 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 71 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 72 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 73 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.032 --> 0.031).  Saving model ...\n",
      "Seed: 3 \tEpoch: 74 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 75 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 76 \tTraining Loss: 0.001 \tValidation Loss: 0.035\n",
      "Seed: 3 \tEpoch: 77 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 78 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 79 \tTraining Loss: 0.010 \tValidation Loss: 0.061\n",
      "Seed: 3 \tEpoch: 80 \tTraining Loss: 0.023 \tValidation Loss: 0.054\n",
      "Seed: 3 \tEpoch: 81 \tTraining Loss: 0.010 \tValidation Loss: 0.036\n",
      "Seed: 3 \tEpoch: 82 \tTraining Loss: 0.006 \tValidation Loss: 0.041\n",
      "Seed: 3 \tEpoch: 83 \tTraining Loss: 0.003 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 84 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 85 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 86 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 87 \tTraining Loss: 0.001 \tValidation Loss: 0.034\n",
      "Seed: 3 \tEpoch: 88 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 89 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 90 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.031 --> 0.031).  Saving model ...\n",
      "Seed: 3 \tEpoch: 91 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 92 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 93 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 94 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 95 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 96 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 97 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 98 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 99 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 100 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.031 --> 0.031).  Saving model ...\n",
      "Seed: 3 \tEpoch: 101 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 102 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 103 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 104 \tTraining Loss: 0.001 \tValidation Loss: 0.033\n",
      "Seed: 3 \tEpoch: 105 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 106 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 107 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 108 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 109 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 110 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 111 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 112 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.031 --> 0.031).  Saving model ...\n",
      "Seed: 3 \tEpoch: 113 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 114 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 115 \tTraining Loss: 0.006 \tValidation Loss: 0.094\n",
      "Seed: 3 \tEpoch: 116 \tTraining Loss: 0.025 \tValidation Loss: 0.037\n",
      "Seed: 3 \tEpoch: 117 \tTraining Loss: 0.011 \tValidation Loss: 0.040\n",
      "Seed: 3 \tEpoch: 118 \tTraining Loss: 0.006 \tValidation Loss: 0.037\n",
      "Seed: 3 \tEpoch: 119 \tTraining Loss: 0.002 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 120 \tTraining Loss: 0.001 \tValidation Loss: 0.036\n",
      "Seed: 3 \tEpoch: 121 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 122 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 123 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.031 --> 0.031).  Saving model ...\n",
      "Seed: 3 \tEpoch: 124 \tTraining Loss: 0.000 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 125 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 126 \tTraining Loss: 0.000 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 127 \tTraining Loss: 0.000 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 128 \tTraining Loss: 0.000 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 129 \tTraining Loss: 0.000 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 130 \tTraining Loss: 0.000 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 131 \tTraining Loss: 0.000 \tValidation Loss: 0.031\n",
      "Validation loss decreased (0.031 --> 0.031).  Saving model ...\n",
      "Seed: 3 \tEpoch: 132 \tTraining Loss: 0.000 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 133 \tTraining Loss: 0.000 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 134 \tTraining Loss: 0.000 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 135 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Validation loss decreased (0.031 --> 0.030).  Saving model ...\n",
      "Seed: 3 \tEpoch: 136 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Seed: 3 \tEpoch: 137 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 138 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 139 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Seed: 3 \tEpoch: 140 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 141 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Seed: 3 \tEpoch: 142 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Validation loss decreased (0.030 --> 0.030).  Saving model ...\n",
      "Seed: 3 \tEpoch: 143 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Seed: 3 \tEpoch: 144 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 145 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 146 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 147 \tTraining Loss: 0.001 \tValidation Loss: 0.030\n",
      "Seed: 3 \tEpoch: 148 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Seed: 3 \tEpoch: 149 \tTraining Loss: 0.001 \tValidation Loss: 0.031\n",
      "Seed: 3 \tEpoch: 150 \tTraining Loss: 0.001 \tValidation Loss: 0.032\n",
      "Finished Training for seed 3 of model ConvNet\n"
     ]
    }
   ],
   "source": [
    "train_loss_hist = []\n",
    "val_loss_hist = []\n",
    "\n",
    "for network in zip(networks):\n",
    "    network = int(''.join(map(str, network)))\n",
    "\n",
    "    for seed in zip(seeds): \n",
    "        seed = int(''.join(map(str, seed)))\n",
    "    \n",
    "        print('-------------------')\n",
    "        print('SEED:', seed)\n",
    "        if network == 0:\n",
    "            print('MODEL: LeNet')\n",
    "        elif network == 1:\n",
    "            print('MODEL: ResNet')\n",
    "        elif network == 2:\n",
    "            print('MODEL: ConvNet')\n",
    "        print('-------------------')\n",
    "\n",
    "        np.random.seed((seed+1)*((seed+network)**(network+1)))\n",
    "        torch.manual_seed((seed+1)*((seed+network)**(network+1)))\n",
    "        random.seed((seed+1)*((seed+network)**(network+1)))\n",
    "        torch.cuda.manual_seed((seed+1)*((seed+network)**(network+1)))\n",
    "\n",
    "        for epoch in range(1, epochs+1):  \n",
    "            train_loss = 0.0\n",
    "            val_loss = 0.0\n",
    "\n",
    "            model[network][seed-1].train()\n",
    "            for data, labels in trainloader:\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "                optimizer[network][seed-1].zero_grad()\n",
    "                outputs = model[network][seed-1](data)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer[network][seed-1].step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            model[network][seed-1].eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data, labels in validloader:\n",
    "                    data, labels = data.to(device), labels.to(device)\n",
    "                    outputs = model[network][seed-1](data)\n",
    "                    loss = criterion(outputs, labels)\n",
    "            \n",
    "                    val_loss += loss.item()\n",
    "\n",
    "\n",
    "            train_loss = train_loss/len(trainloader)\n",
    "            val_loss = val_loss/len(validloader)\n",
    "            train_loss_hist.append(train_loss)\n",
    "            val_loss_hist.append(val_loss)\n",
    "\n",
    "            print('Seed: {} \\tEpoch: {} \\tTraining Loss: {:.3f} \\tValidation Loss: {:.3f}'.format(seed, \n",
    "                epoch, train_loss, val_loss))\n",
    " \n",
    "\n",
    "            if val_loss <= val_loss_min[network][seed-1]:\n",
    "                print('Validation loss decreased ({:.3f} --> {:.3f}).  Saving model ...'.format(\n",
    "                val_loss_min[network][seed-1],\n",
    "                val_loss))\n",
    "                torch.save({\n",
    "                    'model'+str(network)+str(seed)+'_state_dict': deepcopy(model[network][seed-1].state_dict()),\n",
    "                    'optimizer'+str(network)+str(seed)+'_state_dict': deepcopy(optimizer[network][seed-1].state_dict()),\n",
    "                    'epoch': epoch\n",
    "                           }, 'balance_mnist'+str(network)+str(seed)+str('.pt'))\n",
    "                val_loss_min[network][seed-1] = val_loss\n",
    "    \n",
    "        if network == 0:\n",
    "            print('Finished Training for seed', seed, 'of model LeNet')\n",
    "        elif network == 1:\n",
    "            print('Finished Training for seed', seed, 'of model ResNet')\n",
    "        elif network == 2:\n",
    "            print('Finished Training for seed', seed, 'of model ConvNet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83b3e075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:43:08.857729Z",
     "iopub.status.busy": "2022-03-21T14:43:08.857019Z",
     "iopub.status.idle": "2022-03-21T14:43:08.859931Z",
     "shell.execute_reply": "2022-03-21T14:43:08.860313Z",
     "shell.execute_reply.started": "2022-03-21T06:53:25.494645Z"
    },
    "papermill": {
     "duration": 0.482031,
     "end_time": "2022-03-21T14:43:08.860457",
     "exception": false,
     "start_time": "2022-03-21T14:43:08.378426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_hist_splitter(train_loss_hist):\n",
    "    return [train_loss_hist[i*len(train_loss_hist) // len(networks): (i+1)*len(train_loss_hist) // len(networks)] for i in range(len(networks))]\n",
    "\n",
    "def model_seed_splitter(train_loss_hist):\n",
    "    return [train_loss_hist[i*len(train_loss_hist) // len(seeds): (i+1)*len(train_loss_hist) // len(seeds)] for i in range(len(seeds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12a1408c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:43:09.823253Z",
     "iopub.status.busy": "2022-03-21T14:43:09.822097Z",
     "iopub.status.idle": "2022-03-21T14:43:09.827013Z",
     "shell.execute_reply": "2022-03-21T14:43:09.828357Z",
     "shell.execute_reply.started": "2022-03-21T06:53:25.501453Z"
    },
    "papermill": {
     "duration": 0.50405,
     "end_time": "2022-03-21T14:43:09.828622",
     "exception": false,
     "start_time": "2022-03-21T14:43:09.324572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_model_split = model_hist_splitter(train_loss_hist)\n",
    "LeNet_hist = model_seed_splitter(train_model_split[0])\n",
    "ResNet_hist = model_seed_splitter(train_model_split[1])\n",
    "ConvNet_hist = model_seed_splitter(train_model_split[2])\n",
    "\n",
    "LeNet_avg = np.average(LeNet_hist, axis=0) \n",
    "ResNet_avg = np.average(ResNet_hist, axis=0) \n",
    "ConvNet_avg = np.average(ConvNet_hist, axis=0) \n",
    "\n",
    "LeNet_std = np.std(LeNet_hist, axis=0)\n",
    "ResNet_std = np.std(ResNet_hist, axis=0)\n",
    "ConvNet_std = np.std(ConvNet_hist, axis=0)\n",
    "\n",
    "a = np.arange(len(LeNet_avg))\n",
    "b = np.arange(len(ResNet_avg))\n",
    "c = np.arange(len(ConvNet_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1da2e740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:43:11.039863Z",
     "iopub.status.busy": "2022-03-21T14:43:11.038106Z",
     "iopub.status.idle": "2022-03-21T14:43:11.040632Z",
     "shell.execute_reply": "2022-03-21T14:43:11.041081Z",
     "shell.execute_reply.started": "2022-03-21T06:53:25.514843Z"
    },
    "papermill": {
     "duration": 0.468098,
     "end_time": "2022-03-21T14:43:11.041230",
     "exception": false,
     "start_time": "2022-03-21T14:43:10.573132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_model_split = model_hist_splitter(val_loss_hist)\n",
    "LeNet_val_hist = model_seed_splitter(val_model_split[0])\n",
    "ResNet_val_hist = model_seed_splitter(val_model_split[1])\n",
    "ConvNet_val_hist = model_seed_splitter(val_model_split[2])\n",
    "\n",
    "LeNet_val_avg = np.average(LeNet_val_hist, axis=0)\n",
    "ResNet_val_avg = np.average(ResNet_val_hist, axis=0)\n",
    "ConvNet_val_avg = np.average(ConvNet_val_hist, axis=0)\n",
    "\n",
    "LeNet_val_std = np.std(LeNet_val_hist, axis=0)\n",
    "ResNet_val_std = np.std(ResNet_val_hist, axis=0)\n",
    "ConvNet_val_std = np.std(ConvNet_val_hist, axis=0)\n",
    "\n",
    "x = np.arange(len(LeNet_val_avg))\n",
    "y = np.arange(len(ResNet_val_avg))\n",
    "z = np.arange(len(ConvNet_val_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45a4644b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:43:12.020379Z",
     "iopub.status.busy": "2022-03-21T14:43:12.019761Z",
     "iopub.status.idle": "2022-03-21T14:43:16.274498Z",
     "shell.execute_reply": "2022-03-21T14:43:16.274929Z",
     "shell.execute_reply.started": "2022-03-21T06:53:25.527411Z"
    },
    "papermill": {
     "duration": 4.769848,
     "end_time": "2022-03-21T14:43:16.275081",
     "exception": false,
     "start_time": "2022-03-21T14:43:11.505233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x180 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1 ,4, sharey=True)\n",
    "fig.set_size_inches(13, 2.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "#Training Plot\n",
    "axes[0].plot(a, LeNet_avg, color='#C82506', marker='o', markevery=50)\n",
    "axes[0].fill_between(a, LeNet_avg - LeNet_std, LeNet_avg + LeNet_std, color='#C82506', alpha=0.2)\n",
    "\n",
    "axes[0].plot(b, ResNet_avg, color='#0365C0', marker='o', markevery=50)\n",
    "axes[0].fill_between(b, ResNet_avg - ResNet_std, ResNet_avg + ResNet_std, color='#0365C0', alpha=0.2)\n",
    "\n",
    "axes[0].plot(c, ConvNet_avg, color='indigo', marker='o', markevery=50)\n",
    "axes[0].fill_between(c, ConvNet_avg - ConvNet_std, ConvNet_avg + ConvNet_std, color='indigo', alpha=0.2)\n",
    "\n",
    "#Validation Plots\n",
    "axes[1].plot(x, LeNet_val_avg, color='#C82506', marker='o', markevery=50, label=r'$\\mathrm{LeNet-5}$')\n",
    "axes[1].fill_between(x, LeNet_val_avg - LeNet_val_std, LeNet_val_avg + LeNet_val_std, color='#C82506', alpha=0.2)\n",
    "\n",
    "axes[2].plot(y, ResNet_val_avg, color='#0365C0', marker='o', markevery=50, label=r'$\\mathrm{ResNet-18}$')\n",
    "axes[2].fill_between(y, ResNet_val_avg - ResNet_val_std, ResNet_val_avg + ResNet_val_std, color='#0365C0', alpha=0.2)\n",
    "\n",
    "axes[3].plot(z, ConvNet_val_avg, color='indigo', marker='o', markevery=50, label=r'$\\mathrm{ConvNet}$')\n",
    "axes[3].fill_between(z, ConvNet_val_avg - ConvNet_val_std, ConvNet_val_avg + ConvNet_val_std, color='indigo', alpha=0.2)\n",
    "\n",
    "fig.legend(loc='center', bbox_to_anchor=(0.5, 1.02), ncol=3, frameon=False, labelcolor='black')\n",
    "\n",
    "axes[0].set_ylabel(r'$\\mathrm{Loss}$')\n",
    "axes[0].yaxis.labelpad = 12\n",
    "\n",
    "axes[0].grid(color=\"gray\")\n",
    "axes[0].margins(x=0)\n",
    "axes[0].margins(y=0)\n",
    "\n",
    "axes[1].grid(color=\"gray\")\n",
    "axes[1].margins(x=0)\n",
    "axes[1].margins(y=0)\n",
    "\n",
    "axes[2].grid(color=\"gray\")\n",
    "axes[2].margins(x=0)\n",
    "axes[2].margins(y=0)\n",
    "\n",
    "axes[3].grid(color=\"gray\")\n",
    "axes[3].margins(x=0)\n",
    "axes[3].margins(y=0)\n",
    "\n",
    "axes[0].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "axes[1].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "axes[2].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "axes[3].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axes[0].spines[axis].set_color('0')\n",
    "    axes[1].spines[axis].set_color('0')\n",
    "    axes[2].spines[axis].set_color('0')\n",
    "    axes[3].spines[axis].set_color('0')\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axes[0].spines[axis].set_linewidth(1.5)\n",
    "    axes[1].spines[axis].set_linewidth(1.5)\n",
    "    axes[2].spines[axis].set_linewidth(1.5)\n",
    "    axes[3].spines[axis].set_linewidth(1.5)\n",
    "\n",
    "axes[0].axes.xaxis.set_ticklabels([])\n",
    "axes[1].axes.xaxis.set_ticklabels([])\n",
    "axes[2].axes.xaxis.set_ticklabels([])\n",
    "axes[3].axes.xaxis.set_ticklabels([])\n",
    "\n",
    "plt.savefig(\"mnist_balance_final.png\", bbox_inches='tight', dpi=1200)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bd5734c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:43:17.561024Z",
     "iopub.status.busy": "2022-03-21T14:43:17.557973Z",
     "iopub.status.idle": "2022-03-21T14:43:17.913082Z",
     "shell.execute_reply": "2022-03-21T14:43:17.913631Z",
     "shell.execute_reply.started": "2022-03-21T06:53:29.514683Z"
    },
    "papermill": {
     "duration": 1.141779,
     "end_time": "2022-03-21T14:43:17.913837",
     "exception": false,
     "start_time": "2022-03-21T14:43:16.772058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ConvNet(\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "checkpoint1 = torch.load('balance_mnist01.pt')\n",
    "model1.load_state_dict(checkpoint1['model01_state_dict'])\n",
    "optimizer1.load_state_dict(checkpoint1['optimizer01_state_dict'])\n",
    "epoch1 = checkpoint1['epoch']\n",
    "model1.to(device)\n",
    "\n",
    "checkpoint2 = torch.load('balance_mnist02.pt')\n",
    "model2.load_state_dict(checkpoint2['model02_state_dict'])\n",
    "optimizer2.load_state_dict(checkpoint2['optimizer02_state_dict'])\n",
    "epoch2 = checkpoint2['epoch']\n",
    "model2.to(device)\n",
    "\n",
    "checkpoint3 = torch.load('balance_mnist03.pt')\n",
    "model3.load_state_dict(checkpoint3['model03_state_dict'])\n",
    "optimizer3.load_state_dict(checkpoint3['optimizer03_state_dict'])\n",
    "epoch3 = checkpoint3['epoch']\n",
    "model3.to(device)\n",
    "\n",
    "checkpoint4 = torch.load('balance_mnist11.pt')\n",
    "model4.load_state_dict(checkpoint4['model11_state_dict'])\n",
    "optimizer4.load_state_dict(checkpoint4['optimizer11_state_dict'])\n",
    "epoch4 = checkpoint4['epoch']\n",
    "model4.to(device)\n",
    "\n",
    "checkpoint5 = torch.load('balance_mnist12.pt')\n",
    "model5.load_state_dict(checkpoint5['model12_state_dict'])\n",
    "optimizer5.load_state_dict(checkpoint5['optimizer12_state_dict'])\n",
    "epoch5 = checkpoint5['epoch']\n",
    "model5.to(device)\n",
    "\n",
    "checkpoint6 = torch.load('balance_mnist13.pt')\n",
    "model6.load_state_dict(checkpoint6['model13_state_dict'])\n",
    "optimizer6.load_state_dict(checkpoint6['optimizer13_state_dict'])\n",
    "epoch6 = checkpoint6['epoch']\n",
    "model6.to(device)\n",
    "\n",
    "checkpoint7 = torch.load('balance_mnist21.pt')\n",
    "model7.load_state_dict(checkpoint7['model21_state_dict'])\n",
    "optimizer7.load_state_dict(checkpoint7['optimizer21_state_dict'])\n",
    "epoch7 = checkpoint7['epoch']\n",
    "model7.to(device)\n",
    "\n",
    "checkpoint8 = torch.load('balance_mnist22.pt')\n",
    "model8.load_state_dict(checkpoint8['model22_state_dict'])\n",
    "optimizer8.load_state_dict(checkpoint8['optimizer22_state_dict'])\n",
    "epoch8 = checkpoint8['epoch']\n",
    "model8.to(device)\n",
    "\n",
    "checkpoint9 = torch.load('balance_mnist23.pt')\n",
    "model9.load_state_dict(checkpoint9['model23_state_dict'])\n",
    "optimizer9.load_state_dict(checkpoint9['optimizer23_state_dict'])\n",
    "epoch9 = checkpoint9['epoch']\n",
    "model9.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c87e129e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:43:18.942698Z",
     "iopub.status.busy": "2022-03-21T14:43:18.940964Z",
     "iopub.status.idle": "2022-03-21T14:43:18.943354Z",
     "shell.execute_reply": "2022-03-21T14:43:18.943841Z",
     "shell.execute_reply.started": "2022-03-21T06:53:29.747120Z"
    },
    "papermill": {
     "duration": 0.497679,
     "end_time": "2022-03-21T14:43:18.943978",
     "exception": false,
     "start_time": "2022-03-21T14:43:18.446299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_updated = [[model1, model2, model3], [model4, model5, model6], [model7, model8, model9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae8bb290",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:43:19.970084Z",
     "iopub.status.busy": "2022-03-21T14:43:19.969504Z",
     "iopub.status.idle": "2022-03-21T14:43:43.385194Z",
     "shell.execute_reply": "2022-03-21T14:43:43.385753Z",
     "shell.execute_reply.started": "2022-03-21T06:53:29.753777Z"
    },
    "papermill": {
     "duration": 23.978984,
     "end_time": "2022-03-21T14:43:43.385943",
     "exception": false,
     "start_time": "2022-03-21T14:43:19.406959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_accuracy = []\n",
    "test_loss_hist = []\n",
    "labels_list = []\n",
    "pred_list= []\n",
    "class_accuracy_model =[]\n",
    "\n",
    "for network in zip(networks):\n",
    "    network = int(''.join(map(str, network)))\n",
    "\n",
    "    for seed in zip(seeds): \n",
    "        seed = int(''.join(map(str, seed)))\n",
    "        \n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        correct_pred = {classname: 0 for classname in classes}\n",
    "        total_pred = {classname: 0 for classname in classes}\n",
    "        \n",
    "        model_updated[network][seed-1].eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, labels in testloader:\n",
    "                images, labels = data.to(device), labels.to(device)\n",
    "                output = model_updated[network][seed-1](images)\n",
    "    \n",
    "                loss = criterion(output, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                _, pred = torch.max(output, 1)    \n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "                for label, p in zip(labels, pred):\n",
    "                    if label == p:\n",
    "                        correct_pred[classes[label]] += 1\n",
    "                    total_pred[classes[label]] += 1\n",
    "\n",
    "                pred = pred.cpu().detach().numpy()\n",
    "                labels = labels.cpu().detach().numpy()\n",
    "\n",
    "                pred_list.append(pred)\n",
    "                labels_list.append(labels)\n",
    "\n",
    "        test_loss = test_loss/len(testloader)\n",
    "        test_loss_hist.append(test_loss)\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        global_accuracy.append(accuracy)\n",
    "        \n",
    "        for classname, correct_count in correct_pred.items():\n",
    "            model_seed_accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "            class_accuracy_model.append(model_seed_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "151b3e96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:43:44.466210Z",
     "iopub.status.busy": "2022-03-21T14:43:44.465071Z",
     "iopub.status.idle": "2022-03-21T14:43:44.469708Z",
     "shell.execute_reply": "2022-03-21T14:43:44.469149Z",
     "shell.execute_reply.started": "2022-03-21T06:53:51.166271Z"
    },
    "papermill": {
     "duration": 0.530528,
     "end_time": "2022-03-21T14:43:44.469884",
     "exception": false,
     "start_time": "2022-03-21T14:43:43.939356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss for LeNet: 0.042 with standard deviation of 0.000\n",
      "Test Loss for ResNet: 0.025 with standard deviation of 0.001\n",
      "Test Loss for ConvNet: 0.025 with standard deviation of 0.001\n"
     ]
    }
   ],
   "source": [
    "test_model_split = model_hist_splitter(test_loss_hist)\n",
    "LeNet_test_hist = model_seed_splitter(test_model_split[0])\n",
    "ResNet_test_hist = model_seed_splitter(test_model_split[1])\n",
    "ConvNet_test_hist = model_seed_splitter(test_model_split[2])\n",
    "\n",
    "LeNet_test_avg = np.average(LeNet_test_hist, axis=0) \n",
    "ResNet_test_avg = np.average(ResNet_test_hist, axis=0) \n",
    "ConvNet_test_avg = np.average(ConvNet_test_hist, axis=0) \n",
    "\n",
    "LeNet_test_std = np.std(LeNet_test_hist, axis=0)\n",
    "ResNet_test_std = np.std(ResNet_test_hist, axis=0)\n",
    "ConvNet_test_std = np.std(ConvNet_test_hist, axis=0)\n",
    "\n",
    "print('Test Loss for LeNet: {:.3f}'.format(LeNet_test_avg[0]), 'with standard deviation of {:.3f}'.format(LeNet_test_std[0]))\n",
    "print('Test Loss for ResNet: {:.3f}'.format(ResNet_test_avg[0]), 'with standard deviation of {:.3f}'.format(ResNet_test_std[0]))\n",
    "print('Test Loss for ConvNet: {:.3f}'.format(ConvNet_test_avg[0]), 'with standard deviation of {:.3f}'.format(ConvNet_test_std[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5d90675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:43:45.472480Z",
     "iopub.status.busy": "2022-03-21T14:43:45.471200Z",
     "iopub.status.idle": "2022-03-21T14:43:45.474573Z",
     "shell.execute_reply": "2022-03-21T14:43:45.474950Z",
     "shell.execute_reply.started": "2022-03-21T06:53:51.177893Z"
    },
    "papermill": {
     "duration": 0.479413,
     "end_time": "2022-03-21T14:43:45.475092",
     "exception": false,
     "start_time": "2022-03-21T14:43:44.995679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for LeNet: 98.812% with standard deviation of 0.106%\n",
      "Accuracy for ResNet: 99.368% with standard deviation of 0.065%\n",
      "Accuracy for ConvNet: 99.268% with standard deviation of 0.054%\n"
     ]
    }
   ],
   "source": [
    "global_accuracy_new = model_hist_splitter(global_accuracy)\n",
    "global_accuracy_LeNet = model_seed_splitter(global_accuracy_new[0])\n",
    "global_accuracy_ResNet = model_seed_splitter(global_accuracy_new[1])\n",
    "global_accuracy_ConvNet = model_seed_splitter(global_accuracy_new[2])\n",
    "\n",
    "LeNet_average_accuracy = np.average(global_accuracy_LeNet, axis=0)\n",
    "LeNet_accurcy_std = np.std(global_accuracy_LeNet, axis=0)\n",
    "\n",
    "ResNet_average_accuracy = np.average(global_accuracy_ResNet, axis=0)\n",
    "ResNet_accurcy_std = np.std(global_accuracy_ResNet, axis=0)\n",
    "\n",
    "ConvNet_average_accuracy = np.average(global_accuracy_ConvNet, axis=0)\n",
    "ConvNet_accurcy_std = np.std(global_accuracy_ConvNet, axis=0)\n",
    "\n",
    "print('Accuracy for LeNet: {:.3f}%'.format(LeNet_average_accuracy[0]), 'with standard deviation of {:.3f}%'.format(LeNet_accurcy_std[0]))\n",
    "print('Accuracy for ResNet: {:.3f}%'.format(ResNet_average_accuracy[0]), 'with standard deviation of {:.3f}%'.format(ResNet_accurcy_std[0]))\n",
    "print('Accuracy for ConvNet: {:.3f}%'.format(ConvNet_average_accuracy[0]), 'with standard deviation of {:.3f}%'.format(ConvNet_accurcy_std[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a52dea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:43:46.451329Z",
     "iopub.status.busy": "2022-03-21T14:43:46.450347Z",
     "iopub.status.idle": "2022-03-21T14:43:46.461031Z",
     "shell.execute_reply": "2022-03-21T14:43:46.460584Z",
     "shell.execute_reply.started": "2022-03-21T06:53:51.192240Z"
    },
    "papermill": {
     "duration": 0.509227,
     "end_time": "2022-03-21T14:43:46.461155",
     "exception": false,
     "start_time": "2022-03-21T14:43:45.951928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "LeNet Class Accuracy\n",
      "---------------\n",
      "0 : 99.44% with standard deviation of 0.16%\n",
      "1 : 99.25% with standard deviation of 0.38%\n",
      "2 : 99.14% with standard deviation of 0.23%\n",
      "3 : 99.29% with standard deviation of 0.14%\n",
      "4 : 99.03% with standard deviation of 0.14%\n",
      "5 : 98.58% with standard deviation of 0.26%\n",
      "6 : 98.17% with standard deviation of 0.23%\n",
      "7 : 98.77% with standard deviation of 0.56%\n",
      "8 : 98.54% with standard deviation of 0.24%\n",
      "9 : 97.91% with standard deviation of 0.66%\n",
      "\n",
      "\n",
      "---------------\n",
      "ResNet Class Accuracy\n",
      "---------------\n",
      "0 : 99.78% with standard deviation of 0.00%\n",
      "1 : 99.78% with standard deviation of 0.16%\n",
      "2 : 99.33% with standard deviation of 0.18%\n",
      "3 : 99.48% with standard deviation of 0.14%\n",
      "4 : 99.55% with standard deviation of 0.00%\n",
      "5 : 98.99% with standard deviation of 0.09%\n",
      "6 : 99.07% with standard deviation of 0.23%\n",
      "7 : 99.29% with standard deviation of 0.21%\n",
      "8 : 99.66% with standard deviation of 0.09%\n",
      "9 : 98.77% with standard deviation of 0.24%\n",
      "\n",
      "\n",
      "---------------\n",
      "ConvNet Class Accuracy\n",
      "---------------\n",
      "0 : 99.81% with standard deviation of 0.11%\n",
      "1 : 99.70% with standard deviation of 0.11%\n",
      "2 : 99.36% with standard deviation of 0.14%\n",
      "3 : 99.33% with standard deviation of 0.09%\n",
      "4 : 99.48% with standard deviation of 0.19%\n",
      "5 : 99.10% with standard deviation of 0.18%\n",
      "6 : 98.77% with standard deviation of 0.18%\n",
      "7 : 99.18% with standard deviation of 0.19%\n",
      "8 : 99.25% with standard deviation of 0.11%\n",
      "9 : 98.69% with standard deviation of 0.23%\n"
     ]
    }
   ],
   "source": [
    "class_iterable = list(range(len(classes)))\n",
    "\n",
    "class_accuracy_model = np.array_split(class_accuracy_model, 9)\n",
    "class_acc_hist = model_hist_splitter(class_accuracy_model)\n",
    "\n",
    "LeNet_class_acc = model_seed_splitter(class_acc_hist[0])\n",
    "ResNet_class_acc = model_seed_splitter(class_acc_hist[1])\n",
    "ConvNet_class_acc = model_seed_splitter(class_acc_hist[2])\n",
    "\n",
    "LeNet_class_avg = np.average(LeNet_class_acc, axis=0).ravel()\n",
    "ResNet_class_avg = np.average(ResNet_class_acc, axis=0).ravel()\n",
    "ConvNet_class_avg = np.average(ConvNet_class_acc, axis=0).ravel()\n",
    "\n",
    "LeNet_class_std = np.std(LeNet_class_acc, axis=0).ravel()\n",
    "ResNet_class_std = np.std(ResNet_class_acc, axis=0).ravel()\n",
    "ConvNet_class_std = np.std(ConvNet_class_acc, axis=0).ravel()\n",
    "\n",
    "print('---------------')\n",
    "print('LeNet Class Accuracy')\n",
    "print('---------------')\n",
    "for classname, index in zip(classes, class_iterable):\n",
    "    print(classname, ': {:.2f}%'.format(LeNet_class_avg[index]), 'with standard deviation of {:.2f}%'.format(LeNet_class_std[index]))\n",
    "    \n",
    "print('\\n')\n",
    "print('---------------')\n",
    "print('ResNet Class Accuracy')\n",
    "print('---------------')\n",
    "for classname, index in zip(classes, class_iterable):\n",
    "    print(classname, ': {:.2f}%'.format(ResNet_class_avg[index]), 'with standard deviation of {:.2f}%'.format(ResNet_class_std[index]))\n",
    "    \n",
    "print('\\n')\n",
    "print('---------------')\n",
    "print('ConvNet Class Accuracy')\n",
    "print('---------------')\n",
    "for classname, index in zip(classes, class_iterable):   \n",
    "    print(classname, ': {:.2f}%'.format(ConvNet_class_avg[index]), 'with standard deviation of {:.2f}%'.format(ConvNet_class_std[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cdfc14e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:43:47.477431Z",
     "iopub.status.busy": "2022-03-21T14:43:47.476703Z",
     "iopub.status.idle": "2022-03-21T14:43:47.480103Z",
     "shell.execute_reply": "2022-03-21T14:43:47.479163Z",
     "shell.execute_reply.started": "2022-03-21T06:53:51.220521Z"
    },
    "papermill": {
     "duration": 0.512189,
     "end_time": "2022-03-21T14:43:47.480240",
     "exception": false,
     "start_time": "2022-03-21T14:43:46.968051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_list = [item for sublist in pred_list for item in sublist]\n",
    "labels_list = [item for sublist in labels_list for item in sublist]\n",
    "\n",
    "pred_list = np.array_split(pred_list, 9)\n",
    "labels_list = np.array_split(labels_list, 9)\n",
    "\n",
    "pred_model1 = pred_list[0].tolist()\n",
    "pred_model2 = pred_list[1].tolist()\n",
    "pred_model3 = pred_list[2].tolist()\n",
    "pred_model4 = pred_list[3].tolist()\n",
    "pred_model5 = pred_list[4].tolist()\n",
    "pred_model6 = pred_list[5].tolist()\n",
    "pred_model7 = pred_list[6].tolist()\n",
    "pred_model8 = pred_list[7].tolist()\n",
    "pred_model9 = pred_list[8].tolist()\n",
    "\n",
    "labels_list = labels_list[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a5189ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:43:48.437131Z",
     "iopub.status.busy": "2022-03-21T14:43:48.436382Z",
     "iopub.status.idle": "2022-03-21T14:43:49.710235Z",
     "shell.execute_reply": "2022-03-21T14:43:49.710933Z",
     "shell.execute_reply.started": "2022-03-21T06:53:51.271194Z"
    },
    "papermill": {
     "duration": 1.752974,
     "end_time": "2022-03-21T14:43:49.711103",
     "exception": false,
     "start_time": "2022-03-21T14:43:47.958129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_list = [[pred_model1, pred_model2, pred_model3], [pred_model4, pred_model5, pred_model6], [pred_model7, pred_model8, pred_model9]]\n",
    "\n",
    "f1_micro_list, f1_macro_list = [], []\n",
    "gmean_micro_list, gmean_macro_list = [], []\n",
    "bac_list, bac_adj_list = [], []\n",
    "sens_micro_list, sens_macro_list = [], []\n",
    "spec_micro_list, spec_macro_list = [], []\n",
    "prec_micro_list, prec_macro_list = [], []\n",
    "rec_micro_list, rec_macro_list = [], []\n",
    "\n",
    "for network in zip(networks):\n",
    "    network = int(''.join(map(str, network)))\n",
    "\n",
    "    for seed in zip(seeds): \n",
    "        seed = int(''.join(map(str, seed)))\n",
    "        \n",
    "        f1_micro = f1_score(labels_list, pred_list[network][seed-1], average='micro')\n",
    "        f1_macro = f1_score(labels_list, pred_list[network][seed-1], average='macro')\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "        \n",
    "        gmean_micro = geometric_mean_score(labels_list, pred_list[network][seed-1], average='micro')\n",
    "        gmean_macro = geometric_mean_score(labels_list, pred_list[network][seed-1], average='macro')\n",
    "        gmean_micro_list.append(gmean_micro)\n",
    "        gmean_macro_list.append(gmean_macro)\n",
    "        \n",
    "        bac = balanced_accuracy_score(labels_list, pred_list[network][seed-1])\n",
    "        bac_adj = balanced_accuracy_score(labels_list, pred_list[network][seed-1], adjusted=True)\n",
    "        bac_list.append(bac)\n",
    "        bac_adj_list.append(bac_adj)\n",
    "        \n",
    "        sens_micro = sensitivity_score(labels_list, pred_list[network][seed-1], average='micro')\n",
    "        sens_macro = sensitivity_score(labels_list, pred_list[network][seed-1], average='macro')\n",
    "        sens_micro_list.append(sens_micro)\n",
    "        sens_macro_list.append(sens_macro)\n",
    "        \n",
    "        spec_micro = specificity_score(labels_list, pred_list[network][seed-1], average='micro')\n",
    "        spec_macro = specificity_score(labels_list, pred_list[network][seed-1], average='macro')\n",
    "        spec_micro_list.append(sens_micro)\n",
    "        spec_macro_list.append(sens_macro)\n",
    "                                       \n",
    "        prec_micro = precision_score(labels_list, pred_list[network][seed-1], average='micro')\n",
    "        prec_macro = precision_score(labels_list, pred_list[network][seed-1], average='macro')\n",
    "        prec_micro_list.append(prec_micro)\n",
    "        prec_macro_list.append(prec_macro)\n",
    "                                       \n",
    "        rec_micro = recall_score(labels_list, pred_list[network][seed-1], average='micro')\n",
    "        rec_macro = recall_score(labels_list, pred_list[network][seed-1], average='macro')\n",
    "        rec_micro_list.append(rec_micro)\n",
    "        rec_macro_list.append(rec_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f536f60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:43:51.149754Z",
     "iopub.status.busy": "2022-03-21T14:43:51.148068Z",
     "iopub.status.idle": "2022-03-21T14:43:51.193808Z",
     "shell.execute_reply": "2022-03-21T14:43:51.194527Z",
     "shell.execute_reply.started": "2022-03-21T06:53:52.514654Z"
    },
    "papermill": {
     "duration": 0.813447,
     "end_time": "2022-03-21T14:43:51.194678",
     "exception": false,
     "start_time": "2022-03-21T14:43:50.381231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: F1 Micro\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: F1 Micro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: F1 Micro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "\n",
      "\n",
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: F1 Macro\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: F1 Macro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: F1 Macro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "\n",
      "\n",
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: GMean Micro\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: GMean Micro\n",
      "---------------\n",
      "1.00 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: GMean Micro\n",
      "---------------\n",
      "1.00 with standard deviation of 0.00\n",
      "\n",
      "\n",
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: GMean Macro\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: GMean Macro\n",
      "---------------\n",
      "1.00 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: GMean Macro\n",
      "---------------\n",
      "1.00 with standard deviation of 0.00\n",
      "\n",
      "\n",
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: Balanced Accuracy\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: Balanced Accuracy\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: Balanced Accuracy\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "\n",
      "\n",
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: Adjusted Balanced Accuracy\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: Adjusted Balanced Accuracy\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: Adjusted Balanced Accuracy\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "\n",
      "\n",
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: Sensitivity Micro\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: Sensitivity Micro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: Sensitivity Micro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "\n",
      "\n",
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: Sensitivity Macro\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: Sensitivity Macro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: Sensitivity Macro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "\n",
      "\n",
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: Specificity Micro\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: Specificity Micro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: Specificity Micro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "\n",
      "\n",
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: Specificity Macro\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: Specificity Macro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: Specificity Macro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "\n",
      "\n",
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: Precision Micro\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: Precision Micro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: Precision Micro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "\n",
      "\n",
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: Precision Macro\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: Precision Macro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: Precision Macro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "\n",
      "\n",
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: Recall Micro\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: Recall Micro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: Recall Micro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "\n",
      "\n",
      "---------------\n",
      "MODEL: LeNet\n",
      "METRIC: Recall Macro\n",
      "---------------\n",
      " 0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ResNet\n",
      "METRIC: Recall Macro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "---------------\n",
      "MODEL: ConvNet\n",
      "METRIC: Recall Macro\n",
      "---------------\n",
      "0.99 with standard deviation of 0.00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_list = [f1_micro_list, f1_macro_list, gmean_micro_list, gmean_macro_list, bac_list, bac_adj_list, sens_micro_list, sens_macro_list, spec_micro_list, spec_macro_list,\n",
    "                prec_micro_list, prec_macro_list, rec_micro_list, rec_macro_list]\n",
    "\n",
    "names = [\"F1 Micro\", \"F1 Macro\", \"GMean Micro\", \"GMean Macro\", \"Balanced Accuracy\", \"Adjusted Balanced Accuracy\", \"Sensitivity Micro\", \"Sensitivity Macro\", \n",
    "         \"Specificity Micro\", \"Specificity Macro\", \"Precision Micro\", \"Precision Macro\", \"Recall Micro\", \"Recall Macro\"]\n",
    "\n",
    "for metric, name in zip(metrics_list, names):\n",
    "    hist_splitted = model_hist_splitter(metric)\n",
    "\n",
    "    metric_LeNet = model_seed_splitter(hist_splitted[0])\n",
    "    metric_ResNet = model_seed_splitter(hist_splitted[1])\n",
    "    metric_ConvNet = model_seed_splitter(hist_splitted[2])\n",
    "\n",
    "    metric_avg_LeNet = np.average(metric_LeNet, axis=0).ravel()\n",
    "    metric_std_LeNet = np.std(metric_LeNet, axis=0).ravel()\n",
    "\n",
    "    metric_avg_ResNet = np.average(metric_ResNet, axis=0).ravel()\n",
    "    metric_std_ResNet = np.std(metric_ResNet, axis=0).ravel()\n",
    "\n",
    "    metric_avg_ConvNet = np.average(metric_ConvNet, axis=0).ravel()\n",
    "    metric_std_ConvNet = np.std(metric_ConvNet, axis=0).ravel()\n",
    "        \n",
    "    print('---------------')\n",
    "    print('MODEL: LeNet')\n",
    "    print('METRIC:', name)\n",
    "    print('---------------')\n",
    "    print(' {:.2f}'.format(metric_avg_LeNet[0]), 'with standard deviation of {:.2f}'.format(metric_std_LeNet[0]))\n",
    "    \n",
    "    print('---------------')\n",
    "    print('MODEL: ResNet')\n",
    "    print('METRIC:', name)\n",
    "    print('---------------')\n",
    "    print('{:.2f}'.format(metric_avg_ResNet[0]), 'with standard deviation of {:.2f}'.format(metric_std_ResNet[0]))\n",
    "    \n",
    "    print('---------------')\n",
    "    print('MODEL: ConvNet')\n",
    "    print('METRIC:', name)\n",
    "    print('---------------')\n",
    "    print('{:.2f}'.format(metric_avg_ConvNet[0]), 'with standard deviation of {:.2f}'.format(metric_std_ConvNet[0]))\n",
    "    \n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23264.20793,
   "end_time": "2022-03-21T14:43:53.216513",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-21T08:16:09.008583",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0035c5eaa53b46709190a6e21e1e81e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ed85e0051d9b4182b2e7c13b186cf211",
       "placeholder": "​",
       "style": "IPY_MODEL_f8287dcc87af44a5bedbf97e7f1dca1c",
       "value": " 29696/? [00:00&lt;00:00, 1263084.76it/s]"
      }
     },
     "05b3a0ff56e84f3e820f7fa8563d91c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f755281e63114581998ea9b235e6d4d2",
        "IPY_MODEL_e37afcd8b71c406bab894a491d4813cc",
        "IPY_MODEL_142cb9030eb942f8840e2bdb9565031d"
       ],
       "layout": "IPY_MODEL_862b721bed0f468383011f75c91cdc0b"
      }
     },
     "1414afcbe2bb46dd8dace2cc049276da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c3e5167730446e1a88f6fe2021cc5c1",
       "placeholder": "​",
       "style": "IPY_MODEL_698fe8dcc6d5434a9ace4b4fc7f45acc",
       "value": ""
      }
     },
     "142cb9030eb942f8840e2bdb9565031d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_72bd7181d10c44329b476b9e38e3df7f",
       "placeholder": "​",
       "style": "IPY_MODEL_8654b74fc9f1422fa21b9b56a1200f5a",
       "value": " 1649664/? [00:00&lt;00:00, 17752534.43it/s]"
      }
     },
     "1ca859a310ed464abc64ebe561529949": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dd3546cdb66c482096e183761461c1c8",
        "IPY_MODEL_7dd0255359124f619e9fd5a326d5a82b",
        "IPY_MODEL_0035c5eaa53b46709190a6e21e1e81e9"
       ],
       "layout": "IPY_MODEL_bb7b981bc87b498497909e489787e5da"
      }
     },
     "284aeac89a0341f58f656282f96e4ec9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "33004447ff904eb3aac57e486c8b26d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "34b64e6bd68448d1aa4a3e9d2953d30e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d386149ecb640e8b21d4534e331d702": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "47f9c7a9eef7407a93a0ed0c63b39911": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4c3e5167730446e1a88f6fe2021cc5c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5343f13665a94b529b1d3df9ac27158e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5352739b703146ef83db0d85133aee79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "59acbbcd24874a9aaf9cd8cbf7a1be3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_74fccce3e5b74dc2bde8fe0e8c6fc675",
       "max": 9912422.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5352739b703146ef83db0d85133aee79",
       "value": 9912422.0
      }
     },
     "5b6fa446ffdf445fae387c459b315b33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d1f6f3bac0e746008b79d61148997c1e",
       "placeholder": "​",
       "style": "IPY_MODEL_d4a8dd5370ec49f8b773c24cd04528fd",
       "value": ""
      }
     },
     "698fe8dcc6d5434a9ace4b4fc7f45acc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6de79ab19a754c0399add1d17cbd2f13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "701aa18c90154b458e65f2b79b37787e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1414afcbe2bb46dd8dace2cc049276da",
        "IPY_MODEL_59acbbcd24874a9aaf9cd8cbf7a1be3e",
        "IPY_MODEL_f87cd73d17f94bdbb50152f4dce9b10e"
       ],
       "layout": "IPY_MODEL_9ea9b8bb3d584389bb070255756ee8e3"
      }
     },
     "702f7b28066a46daaa718a4c0712078a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5b6fa446ffdf445fae387c459b315b33",
        "IPY_MODEL_85f7e61e9df742619b4993b442b70d81",
        "IPY_MODEL_f2ce485cca334c658f88a4e12d82b4dc"
       ],
       "layout": "IPY_MODEL_34b64e6bd68448d1aa4a3e9d2953d30e"
      }
     },
     "72bd7181d10c44329b476b9e38e3df7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74fccce3e5b74dc2bde8fe0e8c6fc675": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7dd0255359124f619e9fd5a326d5a82b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_82da0b547a2b40119867c8dfed38d500",
       "max": 28881.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ade3b901465c46d4bb76d0f8413ed62f",
       "value": 28881.0
      }
     },
     "8022f1a9a83f48bc8c24fccecbfcda2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82da0b547a2b40119867c8dfed38d500": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "85f7e61e9df742619b4993b442b70d81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_94349e03629a49cfa00c538731c0b63b",
       "max": 4542.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b2d2f43e6e324e3d85ae0ef57826df91",
       "value": 4542.0
      }
     },
     "862b721bed0f468383011f75c91cdc0b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8654b74fc9f1422fa21b9b56a1200f5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "94349e03629a49cfa00c538731c0b63b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ea9b8bb3d584389bb070255756ee8e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ade3b901465c46d4bb76d0f8413ed62f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b2d2f43e6e324e3d85ae0ef57826df91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bb7b981bc87b498497909e489787e5da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d1f6f3bac0e746008b79d61148997c1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d4a0d1de33d54d79b2b589ef691277ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d4a8dd5370ec49f8b773c24cd04528fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d6e9de5fc9a441888320d74496052243": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d86360b1e75940c3966b9894de18a4bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dd3546cdb66c482096e183761461c1c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_33004447ff904eb3aac57e486c8b26d0",
       "placeholder": "​",
       "style": "IPY_MODEL_d6e9de5fc9a441888320d74496052243",
       "value": ""
      }
     },
     "e37afcd8b71c406bab894a491d4813cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d4a0d1de33d54d79b2b589ef691277ad",
       "max": 1648877.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_284aeac89a0341f58f656282f96e4ec9",
       "value": 1648877.0
      }
     },
     "ed85e0051d9b4182b2e7c13b186cf211": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f2ce485cca334c658f88a4e12d82b4dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3d386149ecb640e8b21d4534e331d702",
       "placeholder": "​",
       "style": "IPY_MODEL_d86360b1e75940c3966b9894de18a4bd",
       "value": " 5120/? [00:00&lt;00:00, 8038.09it/s]"
      }
     },
     "f755281e63114581998ea9b235e6d4d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5343f13665a94b529b1d3df9ac27158e",
       "placeholder": "​",
       "style": "IPY_MODEL_47f9c7a9eef7407a93a0ed0c63b39911",
       "value": ""
      }
     },
     "f8287dcc87af44a5bedbf97e7f1dca1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f87cd73d17f94bdbb50152f4dce9b10e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8022f1a9a83f48bc8c24fccecbfcda2c",
       "placeholder": "​",
       "style": "IPY_MODEL_6de79ab19a754c0399add1d17cbd2f13",
       "value": " 9913344/? [00:00&lt;00:00, 7248683.18it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
