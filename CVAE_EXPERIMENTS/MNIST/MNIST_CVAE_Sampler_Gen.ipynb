{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a6e7134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import-ipynb in c:\\users\\anush goel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install import-ipynb\n",
    "import import_ipynb\n",
    "\n",
    "from CVAE_ImbalanceGenerator_MNIST import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4170ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\anush goel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\anush goel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\anush goel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\anush goel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anush goel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\anush goel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\anush goel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anush goel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.30.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anush goel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anush goel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8d39eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c67b7cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "SEED = 0\n",
    "CLASS_SIZE = 10\n",
    "BATCH_SIZE = 32\n",
    "ZDIM = 20\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "# Set seeds\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)   \n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9546861",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader_collection = [trainloader_mnist_1, trainloader_mnist_2, trainloader_mnist_3]\n",
    "trainset_collection = [trainset_mnist_1, trainset_mnist_2, trainset_mnist_3]\n",
    "settings = [0, 1, 2] #we have three different settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0f36709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self, zdim):\n",
    "        super().__init__()\n",
    "        self._zdim = zdim\n",
    "        self._in_units = 28 * 28\n",
    "        hidden_units = 512\n",
    "        self._encoder = nn.Sequential(\n",
    "            nn.Linear(self._in_units + CLASS_SIZE, hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self._to_mean = nn.Linear(hidden_units, zdim)\n",
    "        self._to_lnvar = nn.Linear(hidden_units, zdim)\n",
    "        self._decoder = nn.Sequential(\n",
    "            nn.Linear(zdim + CLASS_SIZE, hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_units, self._in_units),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x, labels):\n",
    "        in_ = torch.empty((x.shape[0], self._in_units + CLASS_SIZE), device=device)\n",
    "        in_[:, :self._in_units] = x\n",
    "        in_[:, self._in_units:] = labels\n",
    "        h = self._encoder(in_)\n",
    "        mean = self._to_mean(h)\n",
    "        lnvar = self._to_lnvar(h)\n",
    "        return mean, lnvar\n",
    "\n",
    "    def decode(self, z, labels):\n",
    "        in_ = torch.empty((z.shape[0], self._zdim + CLASS_SIZE), device=device)\n",
    "        in_[:, :self._zdim] = z\n",
    "        in_[:, self._zdim:] = labels\n",
    "        return self._decoder(in_)\n",
    "\n",
    "\n",
    "def to_onehot(label):\n",
    "    return torch.eye(CLASS_SIZE, device=device, dtype=torch.float32)[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8fb69ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "SETTING: Half-Split Imbalance\n",
      "-------------------\n",
      "epoch: 1 epoch_loss: 166.58161136881512\n",
      "Finished training for SETTING:0\n",
      "-------------------\n",
      "SETTING: MultiMajority\n",
      "-------------------\n",
      "epoch: 1 epoch_loss: 156.54348042429513\n",
      "Finished training for SETTING:1\n",
      "-------------------\n",
      "SETTING: MultiMinority\n",
      "-------------------\n",
      "epoch: 1 epoch_loss: 178.36226130059836\n",
      "Finished training for SETTING:2\n"
     ]
    }
   ],
   "source": [
    "model_1 = CVAE(ZDIM).to(device)\n",
    "model_2 = CVAE(ZDIM).to(device)\n",
    "model_3 = CVAE(ZDIM).to(device)\n",
    "\n",
    "optimizer1 = optim.Adam(model_1.parameters(), lr=1e-3)\n",
    "optimizer2 = optim.Adam(model_2.parameters(), lr=1e-3)\n",
    "optimizer3 = optim.Adam(model_3.parameters(), lr=1e-3)\n",
    "\n",
    "model_collection = [model_1, model_2, model_3]\n",
    "opt_collection = [optimizer1, optimizer2, optimizer3]\n",
    "\n",
    "for setting in zip(settings):\n",
    "    setting = int(''.join(map(str, setting)))\n",
    "\n",
    "    print('-------------------')\n",
    "    if setting == 0:\n",
    "        print('SETTING: Half-Split Imbalance')\n",
    "    elif setting == 1:\n",
    "        print('SETTING: MultiMajority')\n",
    "    elif setting == 2:\n",
    "        print('SETTING: MultiMinority')\n",
    "    print('-------------------')\n",
    "\n",
    "    model_collection[setting].train()\n",
    "    for e in range(NUM_EPOCHS):\n",
    "        train_loss = 0\n",
    "\n",
    "        for i, (images, labels) in enumerate(trainloader_collection[setting]):\n",
    "            labels = to_onehot(labels)\n",
    "            # Reconstruction images\n",
    "            # Encode images\n",
    "            x = images.view(-1, 28*28*1).to(device)\n",
    "            mean, lnvar = model_collection[setting].encode(x, labels)\n",
    "            std = lnvar.exp().sqrt()\n",
    "            epsilon = torch.randn(ZDIM, device=device)\n",
    "        \n",
    "            # Decode latent variables\n",
    "            z = mean + std * epsilon\n",
    "            y = model_collection[setting].decode(z, labels)\n",
    "        \n",
    "            # Compute loss\n",
    "            kld = 0.5 * (1 + lnvar - mean.pow(2) - lnvar.exp()).sum(axis=1)\n",
    "            bce = F.binary_cross_entropy(y, x, reduction='none').sum(axis=1)\n",
    "            loss = (-1 * kld + bce).mean()\n",
    "\n",
    "            # Update model\n",
    "            opt_collection[setting].zero_grad()\n",
    "            loss.backward()\n",
    "            opt_collection[setting].step()\n",
    "            train_loss += loss.item() * x.shape[0]\n",
    "\n",
    "        print(f'epoch: {e + 1} epoch_loss: {train_loss/len(trainset_collection[setting])}')\n",
    "    print(f'Finished training for SETTING:{setting}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9d687f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(NUM, label_name, setting):\n",
    "    model_collection[setting].eval()\n",
    "    output_container = torch.tensor((), device=device)\n",
    "\n",
    "    for i in range(NUM):\n",
    "        z = torch.randn(ZDIM, device=device).unsqueeze(dim=0)\n",
    "        label = torch.tensor([label_name], device=device)\n",
    "        with torch.no_grad():\n",
    "            y = model_collection[setting].decode(z, to_onehot(label))\n",
    "            y = y.reshape(1, 1, 28, 28)\n",
    "\n",
    "        output_container = torch.cat((output_container, y), 0)\n",
    "\n",
    "    return output_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac7a3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_plotter(label_name, setting):\n",
    "    image = image_generator(100, label_name, setting).cpu().detach().numpy()\n",
    "    n = np.random.randint(1, 100)\n",
    "    image = image[n].reshape(28, 28)\n",
    "    fig1, (ax1)= plt.subplots(1, sharex = True, sharey = False)\n",
    "    ax1.title.set_text(f'CVAE Reconstruction of the Class: {label_name} -- Setting: {setting}')\n",
    "    ax1.imshow(image, interpolation ='none', aspect = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a318a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting One (Half-Split Imbalance)\n",
    "CVAE_trainset_setting_one = torch.cat((image_generator(4000, 0, 0), image_generator(4000, 1, 0), image_generator(4000, 2, 0), \n",
    "                                       image_generator(4000, 3, 0), image_generator(4000, 4, 0)), 0)\n",
    "\n",
    "CVAE_train_labels_setting_one = torch.cat((torch.tensor([0]*4000), torch.tensor([1]*4000), torch.tensor([2]*4000), torch.tensor([3]*4000), torch.tensor([4]*4000)), 0)\n",
    "CVAE_setting_one_dataset = TensorDataset(CVAE_trainset_setting_one, CVAE_train_labels_setting_one)\n",
    "\n",
    "CVAE_S1_MNIST_trainloader = DataLoader(CVAE_setting_one_dataset, batch_size=16, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67842854",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting Two (Multimajority)\n",
    "CVAE_setting_two_dataset = TensorDataset(image_generator(5742, 9, 1), torch.tensor([9]*5742))\n",
    "CVAE_S2_MNIST_trainloader = DataLoader(CVAE_setting_two_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deaf12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting Three (Multiminority)\n",
    "CVAE_trainset_setting_three = torch.cat((image_generator(5742, 0, 2), image_generator(5742, 1, 2), image_generator(5742, 2, 2), \n",
    "                                       image_generator(5742, 3, 2), image_generator(5742, 4, 2), image_generator(5742, 5, 2), \n",
    "                                       image_generator(5742, 6, 2), image_generator(5742, 7, 2), image_generator(5742, 8, 2)),  0)\n",
    "\n",
    "CVAE_train_labels_setting_three = torch.cat((torch.tensor([0]*5742), torch.tensor([1]*5742), torch.tensor([2]*5742), torch.tensor([3]*5742), torch.tensor([4]*5742),\n",
    "                                             torch.tensor([5]*5742), torch.tensor([6]*5742), torch.tensor([7]*5742), torch.tensor([8]*5742)), 0)\n",
    "\n",
    "CVAE_setting_three_dataset = TensorDataset(CVAE_trainset_setting_three, CVAE_train_labels_setting_three)\n",
    "\n",
    "CVAE_S3_MNIST_trainloader = DataLoader(CVAE_setting_three_dataset, batch_size=16, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
